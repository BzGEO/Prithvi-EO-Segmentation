{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "222fa278",
      "metadata": {},
      "source": [
        "# Model Evaluation for Prithvi EO Segmentation\n",
        "This notebook demonstrates how to evaluate the Prithvi EO segmentation model using precision, recall, F1 score, and IoU metrics on validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebc6fa7c",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easare377/Prithvi-EO-Segmentation/blob/main/model_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9Mo9lHzQfOeW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Mo9lHzQfOeW",
        "outputId": "edd10e68-caf3-492a-b68e-f45d93b649f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting terratorch\n",
            "  Downloading terratorch-1.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting torch==2.7.0 (from terratorch)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision==0.22.0 (from terratorch)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting rioxarray==0.19.0 (from terratorch)\n",
            "  Downloading rioxarray-0.19.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting albumentations==1.4.6 (from terratorch)\n",
            "  Downloading albumentations-1.4.6-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting albucore==0.0.16 (from terratorch)\n",
            "  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting rasterio==1.4.3 (from terratorch)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting torchmetrics==1.7.1 (from terratorch)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting geopandas==1.0.1 (from terratorch)\n",
            "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting lightly==1.5.20 (from terratorch)\n",
            "  Downloading lightly-1.5.20-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting jsonargparse<=4.35.0 (from terratorch)\n",
            "  Downloading jsonargparse-4.35.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting h5py==3.13.0 (from terratorch)\n",
            "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting mlflow==2.22.0 (from terratorch)\n",
            "  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting lightning==2.5.1.post0 (from terratorch)\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting segmentation-models-pytorch<=0.4.0 (from terratorch)\n",
            "  Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pytest==8.3.5 (from terratorch)\n",
            "  Downloading pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting torchgeo==0.7.0 (from terratorch)\n",
            "  Downloading torchgeo-0.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops==0.8.1 in /usr/local/lib/python3.11/dist-packages (from terratorch) (0.8.1)\n",
            "Requirement already satisfied: timm>=1.0.15 in /usr/local/lib/python3.11/dist-packages (from terratorch) (1.0.19)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from terratorch) (0.34.1)\n",
            "Collecting tifffile==2025.3.30 (from terratorch)\n",
            "  Downloading tifffile-2025.3.30-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.16->terratorch) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.16->terratorch) (4.12.0.88)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.6->terratorch) (1.16.0)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.6->terratorch) (0.25.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.6->terratorch) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.6->terratorch) (4.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.6->terratorch) (1.6.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.6->terratorch) (2.11.7)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas==1.0.1->terratorch) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas==1.0.1->terratorch) (25.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas==1.0.1->terratorch) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas==1.0.1->terratorch) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas==1.0.1->terratorch) (2.1.1)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from lightly==1.5.20->terratorch) (2025.7.14)\n",
            "Collecting hydra-core>=1.0.0 (from lightly==1.5.20->terratorch)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly==1.5.20->terratorch)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly==1.5.20->terratorch) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lightly==1.5.20->terratorch) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly==1.5.20->terratorch) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly==1.5.20->terratorch) (4.67.1)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly==1.5.20->terratorch)\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly==1.5.20->terratorch) (2.5.0)\n",
            "Collecting aenum>=3.1.11 (from lightly==1.5.20->terratorch)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning==2.5.1.post0->terratorch)\n",
            "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting packaging (from geopandas==1.0.1->terratorch)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting mlflow-skinny==2.22.0 (from mlflow==2.22.0->terratorch)\n",
            "  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow==2.22.0->terratorch) (3.1.1)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow==2.22.0->terratorch) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow==2.22.0->terratorch)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow==2.22.0->terratorch)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow==2.22.0->terratorch)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow==2.22.0->terratorch)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow==2.22.0->terratorch) (3.8.2)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow==2.22.0->terratorch) (3.10.0)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow==2.22.0->terratorch) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow==2.22.0->terratorch) (2.0.41)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==8.3.5->terratorch) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest==8.3.5->terratorch) (1.6.0)\n",
            "Collecting affine (from rasterio==1.4.3->terratorch)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio==1.4.3->terratorch) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio==1.4.3->terratorch) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio==1.4.3->terratorch)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio==1.4.3->terratorch)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio==1.4.3->terratorch) (3.2.3)\n",
            "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray==0.19.0->terratorch) (2025.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->terratorch) (3.18.0)\n",
            "Collecting sympy>=1.13.3 (from torch==2.7.0->terratorch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->terratorch) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->terratorch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch==2.7.0->terratorch)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting fiona>=1.8.22 (from torchgeo==0.7.0->terratorch)\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia>=0.7.4 (from torchgeo==0.7.0->terratorch)\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pillow>=9.2 in /usr/local/lib/python3.11/dist-packages (from torchgeo==0.7.0->terratorch) (11.3.0)\n",
            "Collecting rtree>=1.0.1 (from torchgeo==0.7.0->terratorch)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch)\n",
            "  Downloading databricks_sdk-0.61.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (5.29.5)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.35.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->terratorch) (75.2.0)\n",
            "Collecting efficientnet-pytorch>=0.6.1 (from segmentation-models-pytorch<=0.4.0->terratorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pretrainedmodels>=0.7.1 (from segmentation-models-pytorch<=0.4.0->terratorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->terratorch) (1.1.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=1.0.15->terratorch) (0.5.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow==2.22.0->terratorch) (1.1.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow==2.22.0->terratorch) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow==2.22.0->terratorch) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow==2.22.0->terratorch) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow==2.22.0->terratorch) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (3.12.14)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==2.22.0->terratorch)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==2.22.0->terratorch)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly==1.5.20->terratorch) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly==1.5.20->terratorch) (4.9.3)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia>=0.7.4->torchgeo==0.7.0->terratorch)\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: rich<14.0,>=12.3.0 in /usr/local/lib/python3.11/dist-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch) (13.9.4)\n",
            "Collecting tensorboardX<3.0,>=2.2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting bitsandbytes<1.0,>=0.45.2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch)\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow==2.22.0->terratorch) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow==2.22.0->terratorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow==2.22.0->terratorch) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow==2.22.0->terratorch) (1.4.8)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas==1.0.1->terratorch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas==1.0.1->terratorch) (2025.2)\n",
            "Collecting munch (from pretrainedmodels>=0.7.1->segmentation-models-pytorch<=0.4.0->terratorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.6->terratorch) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.6->terratorch) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.6->terratorch) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly==1.5.20->terratorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly==1.5.20->terratorch) (3.10)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.6->terratorch) (2.37.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.6->terratorch) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.6->terratorch) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.6->terratorch) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.22.0->terratorch) (3.2.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->terratorch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1.post0->terratorch) (1.20.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.47.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (3.23.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch) (0.17.0)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch)\n",
            "  Downloading typeshed_client-2.8.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch) (2.19.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch) (0.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (4.9.0)\n",
            "Requirement already satisfied: importlib_resources>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo==0.7.0->terratorch) (6.5.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow==2.22.0->terratorch) (0.6.1)\n",
            "Downloading terratorch-1.0.2-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
            "Downloading albumentations-1.4.6-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.35.0-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly-1.5.20-py3-none-any.whl (851 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.6/851.6 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rioxarray-0.19.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2025.3.30-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchgeo-0.7.0-py3-none-any.whl (604 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.0/605.0 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.61.0-py3-none-any.whl (680 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.6/680.6 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading typeshed_client-2.8.2-py3-none-any.whl (760 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=9491496850ddd586534071b5c8fbbafa0db1dc7154ef5893270d7108e065897d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=b57b6ec8e0d5fb2a43f27765c129bc0c248b14c0b781fb1eeb586716c7eae141\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/5b/96/fd94bc35962d7c6b699e8814db545155ac91d2b95785e1b035\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-cusparselt-cu12, aenum, typeshed-client, triton, tifffile, sympy, rtree, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, lightly_utils, kornia_rs, jsonargparse, h5py, graphql-core, cligj, click-plugins, affine, tensorboardX, rasterio, pytest, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, lightning-utilities, hydra-core, gunicorn, graphql-relay, fiona, docker, alembic, albucore, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, graphene, geopandas, databricks-sdk, torch, rioxarray, opentelemetry-sdk, albumentations, torchvision, torchmetrics, mlflow-skinny, kornia, efficientnet-pytorch, bitsandbytes, pytorch_lightning, pretrainedmodels, mlflow, segmentation-models-pytorch, lightning, lightly, torchgeo, terratorch\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: tifffile\n",
            "    Found existing installation: tifffile 2025.6.11\n",
            "    Uninstalling tifffile-2025.6.11:\n",
            "      Successfully uninstalled tifffile-2025.6.11\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.14.0\n",
            "    Uninstalling h5py-3.14.0:\n",
            "      Successfully uninstalled h5py-3.14.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.4.1\n",
            "    Uninstalling pytest-8.4.1:\n",
            "      Successfully uninstalled pytest-8.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.24\n",
            "    Uninstalling albucore-0.0.24:\n",
            "      Successfully uninstalled albucore-0.0.24\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: geopandas\n",
            "    Found existing installation: geopandas 1.1.1\n",
            "    Uninstalling geopandas-1.1.1:\n",
            "      Successfully uninstalled geopandas-1.1.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aenum-3.1.16 affine-2.4.0 albucore-0.0.16 albumentations-1.4.6 alembic-1.16.4 bitsandbytes-0.46.1 click-plugins-1.1.1.2 cligj-0.7.2 databricks-sdk-0.61.0 docker-7.1.0 efficientnet-pytorch-0.7.1 fiona-1.10.1 geopandas-1.0.1 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 h5py-3.13.0 hydra-core-1.3.2 jsonargparse-4.35.0 kornia-0.8.1 kornia_rs-0.1.9 lightly-1.5.20 lightly_utils-0.0.2 lightning-2.5.1.post0 lightning-utilities-0.15.0 mlflow-2.22.0 mlflow-skinny-2.22.0 munch-4.0.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 packaging-24.2 pretrainedmodels-0.7.4 pytest-8.3.5 pytorch_lightning-2.5.2 rasterio-1.4.3 rioxarray-0.19.0 rtree-1.4.0 segmentation-models-pytorch-0.4.0 sympy-1.14.0 tensorboardX-2.6.4 terratorch-1.0.2 tifffile-2025.3.30 torch-2.7.0 torchgeo-0.7.0 torchmetrics-1.7.1 torchvision-0.22.0 triton-3.3.0 typeshed-client-2.8.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "646f9850c7e048c48e7f5b253cae4e11",
              "pip_warning": {
                "packages": [
                  "packaging",
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install terratorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f711cdc1",
      "metadata": {},
      "source": [
        "# Install Dependencies and Mount Google Drive\n",
        "Install required packages and mount Google Drive for accessing validation data and model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "LtZd0E7chkMP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtZd0E7chkMP",
        "outputId": "fe66b75c-f07c-42e3-b481-ef3c56ae8995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a0868d4",
      "metadata": {
        "id": "9a0868d4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3630d155",
      "metadata": {},
      "source": [
        "# Import Libraries and Define Dataset Class\n",
        "Import necessary libraries and define the custom dataset class for loading TFRecord validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "54f11476",
      "metadata": {
        "id": "54f11476"
      },
      "outputs": [],
      "source": [
        "import os, struct, io, mmap\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def zero_pad_array(arr, target_hw):\n",
        "    th, tw = target_hw\n",
        "    h, w = arr.shape[:2]\n",
        "    pad_h = max(th - h, 0)\n",
        "    pad_w = max(tw - w, 0)\n",
        "    pad = ((pad_h // 2, pad_h - pad_h // 2),\n",
        "           (pad_w // 2, pad_w - pad_w // 2))\n",
        "    if arr.ndim == 3: pad += ((0, 0),)\n",
        "    return np.pad(arr, pad, mode='constant')\n",
        "\n",
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def zero_pad_array(arr, target_hw):\n",
        "    th, tw = target_hw\n",
        "    h, w = arr.shape[:2]\n",
        "    pad_h = max(th - h, 0)\n",
        "    pad_w = max(tw - w, 0)\n",
        "    pad = ((pad_h // 2, pad_h - pad_h // 2),\n",
        "           (pad_w // 2, pad_w - pad_w // 2))\n",
        "    if arr.ndim == 3: pad += ((0, 0),)\n",
        "    return np.pad(arr, pad, mode='constant')\n",
        "\n",
        "\n",
        "class MineFootprintTFRecordDataset(Dataset):\n",
        "    MEAN = np.array([1635.8452, 1584.4594, 1456.8425, 2926.6663, 2135.001, 1352.7313], dtype=np.float32)\n",
        "    STD  = np.array([884.3994, 815.4016, 839.0293, 1055.6382, 751.4628, 628.5323], dtype=np.float32)\n",
        "\n",
        "    _feature_desc = {\n",
        "        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"mask_raw\":  tf.io.FixedLenFeature([], tf.string),\n",
        "        \"height\":    tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"width\":     tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"channels\":  tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"temporal_coords\": tf.io.FixedLenFeature([2], tf.float32),\n",
        "        \"location_coords\": tf.io.FixedLenFeature([2], tf.float32),\n",
        "    }\n",
        "\n",
        "    def __init__(self, tfrecord_file, transform=None, pad_to=(224, 224)):\n",
        "        super().__init__()\n",
        "        self.tfrecord_path = os.fspath(tfrecord_file)\n",
        "        self.transform = transform\n",
        "        self.pad_to = pad_to\n",
        "\n",
        "        # ---- build a list of byte offsets ----------------------------------\n",
        "        self._offsets = self._scan_index()\n",
        "        self._fh = open(self.tfrecord_path, 'rb')\n",
        "\n",
        "    def _scan_index(self):\n",
        "        \"\"\"Return a list with the starting byte of each record.\"\"\"\n",
        "        offsets = []\n",
        "        with open(self.tfrecord_path, 'rb') as f:\n",
        "            pos = 0\n",
        "            while True:\n",
        "                header = f.read(12)\n",
        "                if not header: break\n",
        "                rec_len = struct.unpack('<Q', header[:8])[0]\n",
        "                offsets.append(pos)\n",
        "                pos += 12 + rec_len + 4\n",
        "                f.seek(pos)\n",
        "        return offsets\n",
        "\n",
        "    def _read_record(self, offset):\n",
        "        \"\"\"Seek & return the serialised Example bytes of one record.\"\"\"\n",
        "        self._fh.seek(offset)\n",
        "        header = self._fh.read(12)\n",
        "        rec_len = struct.unpack('<Q', header[:8])[0]\n",
        "        data = self._fh.read(rec_len)\n",
        "        _ = self._fh.read(4)\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._offsets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        serialised = self._read_record(self._offsets[idx])\n",
        "        ex = tf.io.parse_single_example(serialised, self._feature_desc)\n",
        "\n",
        "        h = int(ex[\"height\"])\n",
        "        w = int(ex[\"width\"])\n",
        "        c = int(ex[\"channels\"])\n",
        "\n",
        "        img = np.frombuffer(ex[\"image_raw\"].numpy(), dtype=np.float32).reshape((h, w, c))\n",
        "        msk = np.frombuffer(ex[\"mask_raw\"].numpy(),  dtype=np.uint8).reshape((h, w))\n",
        "\n",
        "        img = np.nan_to_num(img, nan=0.0)\n",
        "        msk = np.nan_to_num(msk.astype(np.float32), nan=0.0).astype(np.uint8)\n",
        "\n",
        "        img = (img - self.MEAN) / self.STD\n",
        "        img = zero_pad_array(img, self.pad_to)\n",
        "        msk = zero_pad_array(msk, self.pad_to)\n",
        "\n",
        "        temporal_coords = ex['temporal_coords'].numpy().astype(np.float32)   # (2,)\n",
        "        location_coords = ex['location_coords'].numpy().astype(np.float32)   # (2,)\n",
        "\n",
        "        temporal_coords = np.expand_dims(temporal_coords, axis=0)            # (1, 2)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img, mask=msk)\n",
        "            img, msk   = augmented[\"image\"], augmented[\"mask\"]\n",
        "        else:\n",
        "            img = torch.from_numpy(img.transpose(2, 0, 1))  # (C,H,W)\n",
        "            msk = torch.from_numpy(msk)\n",
        "\n",
        "        out = {\n",
        "            \"image\": img.float(),\n",
        "            \"temporal_coords\": torch.from_numpy(temporal_coords),\n",
        "            \"location_coords\": torch.from_numpy(location_coords),\n",
        "            \"mask\": msk.long()\n",
        "        }\n",
        "        return out\n",
        "\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            if hasattr(self, '_fh') and not self._fh.closed:\n",
        "                self._fh.close()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.RandomRotate90(p=0.7),       # p: probability of applying this transform\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "53a1222a",
      "metadata": {
        "id": "53a1222a"
      },
      "outputs": [],
      "source": [
        "val_file_path = '/content/drive/MyDrive/SCO_training/ssm_footprint_val.tfrecord'\n",
        "val_dataset = MineFootprintTFRecordDataset(val_file_path, transform=transform)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True,drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbb3f05",
      "metadata": {},
      "source": [
        "# Prepare Validation Data Loader\n",
        "Load the validation TFRecord file and prepare the DataLoader for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "BMWb_mpkiDs6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMWb_mpkiDs6",
        "outputId": "1ae6e9e6-c1ed-4386-ab76-e03d153ffad5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Decoder FCNDecoder does not have an `includes_head` attribute. Falling back to the value of the registry.\n"
          ]
        }
      ],
      "source": [
        "from terratorch.tasks import SemanticSegmentationTask\n",
        "\n",
        "model = SemanticSegmentationTask(\n",
        "    model_factory=\"EncoderDecoderFactory\",\n",
        "    model_args=dict(\n",
        "        backbone=\"terratorch_prithvi_eo_v2_300_tl\",\n",
        "        backbone_pretrained=False,\n",
        "        backbone_img_size=224,\n",
        "        backbone_bands=[\"BLUE\",\"GREEN\",\"RED\",\"NIR_NARROW\",\"SWIR_1\",\"SWIR_2\"],\n",
        "        necks=[{\"name\":\"SelectIndices\", \"indices\":[1, 5,11,17,23]},\n",
        "               {\"name\":\"ReshapeTokensToImage\"}],\n",
        "        decoder=\"FCNDecoder\",\n",
        "        decoder_channels=256,\n",
        "        num_classes=3,\n",
        "        head_dropout=0.1,\n",
        "    ),\n",
        "    freeze_backbone=False,\n",
        "    freeze_decoder=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa7e6063",
      "metadata": {},
      "source": [
        "# Load and Prepare Segmentation Model\n",
        "Instantiate the Prithvi EO segmentation model and load pretrained weights for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "36fb6b1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36fb6b1f",
        "outputId": "b451a9a6-9396-40d8-d697-4bb6dc2c662d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SemanticSegmentationTask(\n",
              "  (model): PixelWiseModel(\n",
              "    (encoder): PrithviViT(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv3d(6, 1024, kernel_size=(1, 16, 16), stride=(1, 16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (temporal_embed_enc): TemporalEncoder()\n",
              "      (location_embed_enc): LocationEncoder()\n",
              "      (blocks): ModuleList(\n",
              "        (0-23): 24 x Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): FCNDecoder(\n",
              "      (convs): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): ConvTranspose2d(1024, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): Norm2d(\n",
              "            (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "          (3): GELU(approximate='none')\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): Norm2d(\n",
              "            (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "          (3): GELU(approximate='none')\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): Norm2d(\n",
              "            (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "          (3): GELU(approximate='none')\n",
              "        )\n",
              "        (3): Sequential(\n",
              "          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): Norm2d(\n",
              "            (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "          (3): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (head): SegmentationHead(\n",
              "      (head): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): Dropout(p=0.1, inplace=False)\n",
              "        (2): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (aux_heads): ModuleDict()\n",
              "    (neck): Sequential(\n",
              "      (0): SelectIndices()\n",
              "      (1): ReshapeTokensToImage()\n",
              "    )\n",
              "  )\n",
              "  (criterion): CrossEntropyLoss()\n",
              "  (train_metrics): MetricCollection(\n",
              "    (Multiclass_Accuracy): MulticlassAccuracy()\n",
              "    (Multiclass_Accuracy_Class): ClasswiseWrapper(\n",
              "      (metric): MulticlassAccuracy()\n",
              "    )\n",
              "    (Multiclass_F1_Score): MulticlassF1Score()\n",
              "    (Multiclass_Jaccard_Index): MulticlassJaccardIndex()\n",
              "    (Multiclass_Jaccard_Index_Class): ClasswiseWrapper(\n",
              "      (metric): MulticlassJaccardIndex()\n",
              "    )\n",
              "    (Multiclass_Jaccard_Index_Micro): MulticlassJaccardIndex(),\n",
              "    prefix=train/\n",
              "  )\n",
              "  (val_metrics): MetricCollection(\n",
              "    (Multiclass_Accuracy): MulticlassAccuracy()\n",
              "    (Multiclass_Accuracy_Class): ClasswiseWrapper(\n",
              "      (metric): MulticlassAccuracy()\n",
              "    )\n",
              "    (Multiclass_F1_Score): MulticlassF1Score()\n",
              "    (Multiclass_Jaccard_Index): MulticlassJaccardIndex()\n",
              "    (Multiclass_Jaccard_Index_Class): ClasswiseWrapper(\n",
              "      (metric): MulticlassJaccardIndex()\n",
              "    )\n",
              "    (Multiclass_Jaccard_Index_Micro): MulticlassJaccardIndex(),\n",
              "    prefix=val/\n",
              "  )\n",
              "  (test_metrics): ModuleList(\n",
              "    (0): MetricCollection(\n",
              "      (Multiclass_Accuracy): MulticlassAccuracy()\n",
              "      (Multiclass_Accuracy_Class): ClasswiseWrapper(\n",
              "        (metric): MulticlassAccuracy()\n",
              "      )\n",
              "      (Multiclass_F1_Score): MulticlassF1Score()\n",
              "      (Multiclass_Jaccard_Index): MulticlassJaccardIndex()\n",
              "      (Multiclass_Jaccard_Index_Class): ClasswiseWrapper(\n",
              "        (metric): MulticlassJaccardIndex()\n",
              "      )\n",
              "      (Multiclass_Jaccard_Index_Micro): MulticlassJaccardIndex(),\n",
              "      prefix=test/\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_save_path  = Path(\"/content/drive/MyDrive/SCO_training/prithvi_state_dict.pt\")\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "baed90de",
      "metadata": {
        "id": "baed90de"
      },
      "outputs": [],
      "source": [
        "def calculate_precision_recall(ground_truth_mask, predicted_mask, num_classes):\n",
        "    # print(ground_truth_mask.shape, predicted_mask.shape)\n",
        "    precision = [None] * num_classes  # np.zeros(num_classes)\n",
        "    recall = [None] * num_classes  # np.zeros(num_classes)\n",
        "    precision_dict = dict()\n",
        "    recall_dict = dict()\n",
        "    for class_id in range(num_classes):\n",
        "        true_positives = np.sum(\n",
        "            (ground_truth_mask == class_id) & (predicted_mask == class_id))\n",
        "        false_positives = np.sum(\n",
        "            (ground_truth_mask != class_id) & (predicted_mask == class_id))\n",
        "        false_negatives = np.sum(\n",
        "            (ground_truth_mask == class_id) & (predicted_mask != class_id))\n",
        "        p = None\n",
        "        r = None\n",
        "        if true_positives + false_positives != 0:\n",
        "            p = true_positives / (true_positives + false_positives)\n",
        "        if true_positives + false_negatives != 0:\n",
        "            r = true_positives / (true_positives + false_negatives)\n",
        "        precision_dict[class_id] = p\n",
        "        recall_dict[class_id] = r\n",
        "    return precision_dict, recall_dict\n",
        "\n",
        "\n",
        "def calc_f1_score(precision, recall):\n",
        "    if precision is None or recall is None or (precision + recall) == 0:\n",
        "        return None\n",
        "    return (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "\n",
        "def calculate_raw_scores(ground_truth_mask, predicted_mask, num_classes):\n",
        "    # print(ground_truth_mask.shape, predicted_mask.shape)\n",
        "    # precision = [None] * num_classes  # np.zeros(num_classes)\n",
        "    # recall = [None] * num_classes  # np.zeros(num_classes)\n",
        "    # precision_dict = dict()\n",
        "    # recall_dict = dict()\n",
        "    true_positives_dict = dict()\n",
        "    false_positives_dict = dict()\n",
        "    false_negatives_dict = dict()\n",
        "    for class_id in range(num_classes):\n",
        "        true_positives = np.sum(\n",
        "            (ground_truth_mask == class_id) & (predicted_mask == class_id))\n",
        "        false_positives = np.sum(\n",
        "            (ground_truth_mask != class_id) & (predicted_mask == class_id))\n",
        "        false_negatives = np.sum(\n",
        "            (ground_truth_mask == class_id) & (predicted_mask != class_id))\n",
        "        true_positives_dict[class_id] = true_positives\n",
        "        false_positives_dict[class_id] = false_positives\n",
        "        false_negatives_dict[class_id] = false_negatives\n",
        "        # p = None\n",
        "        # r = None\n",
        "        # if true_positives + false_positives != 0:\n",
        "        #     p = true_positives / (true_positives + false_positives)\n",
        "        # if true_positives + false_negatives != 0:\n",
        "        #     r = true_positives / (true_positives + false_negatives)\n",
        "        # precision_dict[class_id] = p\n",
        "        # recall_dict[class_id] = r\n",
        "    return true_positives_dict, false_positives_dict, false_negatives_dict\n",
        "\n",
        "def calculate_mean_precision_recall(model, val_datagen, num_classes):\n",
        "    # Replace with the actual number of classes in your model\n",
        "    # num_classes = 3\n",
        "    # precision_total_dict = dict()\n",
        "    # recall_total_dict = dict()\n",
        "    total_true_positives_dict = dict()\n",
        "    total_false_positives_dict = dict()\n",
        "    total_false_negatives_dict = dict()\n",
        "    precision_scores = np.zeros(num_classes)\n",
        "    recall_scores = np.zeros(num_classes)\n",
        "    f1_scores = np.zeros(num_classes)\n",
        "    # class_iou_scores = np.zeros(num_classes)\n",
        "    # class_counts = np.zeros(num_classes)\n",
        "\n",
        "    # Iterate over the validation data generator\n",
        "    for images, labels in val_datagen:\n",
        "        for image, label in zip(images, labels):\n",
        "            # Predict the labels using the model\n",
        "            predictions = model.predict(np.array([image]), verbose=False)\n",
        "            predicted_classes = np.argmax(predictions, axis=3)\n",
        "            # print(predicted_classes.shape)\n",
        "            true_positives_dict, false_positives_dict, false_negatives_dict = calculate_raw_scores(\n",
        "                label, predicted_classes[0], num_classes)\n",
        "            # print(precision_dict, recall_dict)\n",
        "            for class_id in range(num_classes):\n",
        "                # p = precision_dict.get(class_id)\n",
        "                # r = recall_dict.get(class_id)\n",
        "                ttp = total_true_positives_dict.get(class_id, 0.0)\n",
        "                tfp = total_false_positives_dict.get(class_id, 0.0)\n",
        "                tfn = total_false_negatives_dict.get(class_id, 0.0)\n",
        "                ttp += true_positives_dict[class_id]\n",
        "                tfp += false_positives_dict[class_id]\n",
        "                tfn += false_negatives_dict[class_id]\n",
        "                total_true_positives_dict[class_id] = ttp\n",
        "                total_false_positives_dict[class_id] = tfp\n",
        "                total_false_negatives_dict[class_id] = tfn\n",
        "                # if p != None:\n",
        "                #     pt = precision_total_dict.get(class_id, [0, 0])\n",
        "                #     pt[0] += p\n",
        "                #     pt[1] += 1\n",
        "                #     precision_total_dict[class_id] = pt\n",
        "                # if r != None:\n",
        "                #     rt = recall_total_dict.get(class_id, [0, 0])\n",
        "                #     rt[0] += r\n",
        "                #     rt[1] += 1\n",
        "                #     recall_total_dict[class_id] = rt\n",
        "        # Compute IoU scores for each class\n",
        "        # for class_id in range(num_classes):\n",
        "\n",
        "    # Calculate average IoU scores for each class\n",
        "    # class_iou_scores /= class_counts\n",
        "    for class_id in range(num_classes):\n",
        "        ttp = total_true_positives_dict.get(class_id)\n",
        "        tfp = total_false_positives_dict.get(class_id)\n",
        "        tfn = total_false_negatives_dict.get(class_id)\n",
        "        p = None\n",
        "        r = None\n",
        "        if ttp + tfp != 0:\n",
        "            p = ttp / (ttp + tfp)\n",
        "        if ttp + tfn != 0:\n",
        "            r = ttp / (ttp + tfn)\n",
        "        # pt = precision_total_dict.get(x)\n",
        "        # rt = recall_total_dict.get(x)\n",
        "        # total_score = pt[0]\n",
        "        precision_scores[class_id] = p\n",
        "        # rt = recall_total_dict.get(x)\n",
        "        # total_score = pt[0]\n",
        "        recall_scores[class_id] = r\n",
        "        f1_scores[class_id] = calc_f1_score(p, r)\n",
        "\n",
        "    # Create a DataFrame with class labels and corresponding IoU scores\n",
        "    iou_df = pd.DataFrame(\n",
        "        {'class_val': range(num_classes), 'precision': precision_scores, 'recall': recall_scores, 'f1 score': f1_scores})\n",
        "    # print(precision_total_dict)\n",
        "    return iou_df\n",
        "\n",
        "\n",
        "def calculate_mean_precision_recall(model_func, model, val_datagen, num_classes, device):\n",
        "    total_true_positives_dict = {c: 0 for c in range(num_classes)}\n",
        "    total_false_positives_dict = {c: 0 for c in range(num_classes)}\n",
        "    total_false_negatives_dict = {c: 0 for c in range(num_classes)}\n",
        "\n",
        "    # For batchwise prediction, create predictor\n",
        "    predict = model_func(model, device)\n",
        "\n",
        "    for batch in val_datagen:\n",
        "        # images: batch of shape [B, C, H, W] (torch.Tensor or np.ndarray)\n",
        "        # labels: batch of shape [B, H, W] (numpy or torch)\n",
        "        images = batch['image'].to(device)\n",
        "        masks = batch['mask'].to(device)\n",
        "        temporal_coords=batch[\"temporal_coords\"].to(device)\n",
        "        location_coords=batch[\"location_coords\"].to(device)\n",
        "        # if torch.is_tensor(images):\n",
        "        #     images = images.to(device)\n",
        "        pred_masks = predict(images, temporal_coords=temporal_coords, location_coords=location_coords)  # shape: [B, H, W] (np.ndarray)\n",
        "        if torch.is_tensor(masks):\n",
        "            masks = masks.cpu().numpy()\n",
        "        for pred_mask, label in zip(pred_masks, masks):\n",
        "            true_positives_dict, false_positives_dict, false_negatives_dict = calculate_raw_scores(\n",
        "                label, pred_mask, num_classes)\n",
        "            for class_id in range(num_classes):\n",
        "                total_true_positives_dict[class_id] += true_positives_dict[class_id]\n",
        "                total_false_positives_dict[class_id] += false_positives_dict[class_id]\n",
        "                total_false_negatives_dict[class_id] += false_negatives_dict[class_id]\n",
        "\n",
        "    # Aggregate results\n",
        "    precision_scores = np.zeros(num_classes)\n",
        "    recall_scores = np.zeros(num_classes)\n",
        "    f1_scores = np.zeros(num_classes)\n",
        "    iou_scores = np.zeros(num_classes)\n",
        "\n",
        "    for class_id in range(num_classes):\n",
        "        ttp = total_true_positives_dict[class_id]\n",
        "        tfp = total_false_positives_dict[class_id]\n",
        "        tfn = total_false_negatives_dict[class_id]\n",
        "        denom = ttp + tfp + tfn\n",
        "        iou = ttp / denom if denom != 0 else None\n",
        "        p = ttp / (ttp + tfp) if (ttp + tfp) != 0 else None\n",
        "        r = ttp / (ttp + tfn) if (ttp + tfn) != 0 else None\n",
        "        f1 = calc_f1_score(p, r)\n",
        "        precision_scores[class_id] = p if p is not None else np.nan\n",
        "        recall_scores[class_id] = r if r is not None else np.nan\n",
        "        f1_scores[class_id] = f1 if f1 is not None else np.nan\n",
        "        iou_scores[class_id] = iou if iou is not None else np.nan\n",
        "\n",
        "    iou_df = pd.DataFrame({\n",
        "        'class_val': range(num_classes),\n",
        "        'iou': iou_scores,\n",
        "        'precision': precision_scores,\n",
        "        'recall': recall_scores,\n",
        "        'f1 score': f1_scores\n",
        "    })\n",
        "    return iou_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b7b1f92",
      "metadata": {},
      "source": [
        "# Define Evaluation Metrics and Functions\n",
        "Implement functions to calculate precision, recall, F1 score, and IoU for model predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3c5e4931",
      "metadata": {
        "id": "3c5e4931"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def model_predict(model, device):\n",
        "    \"\"\"\n",
        "    Returns a function that predicts class masks from input tensors using a model.\n",
        "    Handles both single image and batch input.\n",
        "    \"\"\"\n",
        "    def predict(images, temporal_coords, location_coords):\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if isinstance(images, np.ndarray):\n",
        "                images = torch.from_numpy(images)\n",
        "            images = images.to(device)\n",
        "            if images.dim() == 3:  # Single image, shape: [C, H, W]\n",
        "                images = images.unsqueeze(0)\n",
        "            outputs = model(images).output  # [B, num_classes, H, W]\n",
        "            pred_masks = torch.argmax(outputs, dim=1)  # [B, H, W]\n",
        "            pred_masks = pred_masks.cpu().numpy()\n",
        "        return pred_masks\n",
        "    return predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6d2ba9a5",
      "metadata": {
        "id": "6d2ba9a5"
      },
      "outputs": [],
      "source": [
        "def model_predict(model, device):\n",
        "    \"\"\"\n",
        "    Returns a function that predicts class masks from input tensors using a model.\n",
        "    Handles both single image and batch input.\n",
        "    Supports optional temporal_coords and location_coords.\n",
        "    \"\"\"\n",
        "    def predict(images, temporal_coords=None, location_coords=None):\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if isinstance(images, np.ndarray):\n",
        "                images = torch.from_numpy(images)\n",
        "            images = images.to(device)\n",
        "            if images.dim() == 3:  # Single image, shape: [C, H, W]\n",
        "                images = images.unsqueeze(0)\n",
        "\n",
        "            # Prepare optional kwargs\n",
        "            kwargs = {}\n",
        "            if temporal_coords is not None:\n",
        "                if isinstance(temporal_coords, np.ndarray):\n",
        "                    temporal_coords = torch.from_numpy(temporal_coords)\n",
        "                kwargs[\"temporal_coords\"] = temporal_coords.to(device)\n",
        "            if location_coords is not None:\n",
        "                if isinstance(location_coords, np.ndarray):\n",
        "                    location_coords = torch.from_numpy(location_coords)\n",
        "                kwargs[\"location_coords\"] = location_coords.to(device)\n",
        "\n",
        "            outputs = model(images, **kwargs).output  # [B, num_classes, H, W]\n",
        "            pred_masks = torch.argmax(outputs, dim=1)  # [B, H, W]\n",
        "            pred_masks = pred_masks.cpu().numpy()\n",
        "        return pred_masks\n",
        "    return predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a8170d2",
      "metadata": {},
      "source": [
        "# Define Model Prediction Helper Functions\n",
        "Create helper functions to run model inference and obtain predicted masks for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "feb058be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feb058be",
        "outputId": "feedb3f4-d4ef-48aa-c525-1ac3028f811b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yonXZF_YgyxI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "yonXZF_YgyxI",
        "outputId": "8c82cdae-ebf2-4793-8667-094bb57f6b74"
      },
      "outputs": [],
      "source": [
        "results_df = calculate_mean_precision_recall(model_predict, model, val_loader, 3, device)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "affde3ea",
      "metadata": {},
      "source": [
        "# Run Evaluation and Display Results\n",
        "Run the evaluation metrics on the validation set and display precision, recall, F1 score, and IoU for each class."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
