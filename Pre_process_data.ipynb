{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b21793c3",
      "metadata": {},
      "source": [
        "# Preprocessing Pipeline for Sentinel Data\n",
        "This notebook covers the full pipeline for preprocessing Sentinel satellite images and masks for segmentation tasks, including downloading, patching, encoding, and TFRecord export."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86fa84d2",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easare377/Prithvi-EO-Segmentation/blob/main/Pre_process_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c043b37c",
      "metadata": {},
      "source": [
        "# Mount Google Drive and Set Up Paths\n",
        "Mount Google Drive and define all necessary paths for data storage and access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd62683",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43d5815",
      "metadata": {
        "id": "e43d5815"
      },
      "outputs": [],
      "source": [
        "from osgeo import gdal, osr\n",
        "from osgeo import gdal_array\n",
        "from osgeo import osr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import uuid\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "767e4b02",
      "metadata": {
        "id": "767e4b02"
      },
      "outputs": [],
      "source": [
        "data_path = r'/content/drive/MyDrive/SCO_training'\n",
        "segmentation_path = os.path.join(data_path, 'segmentation')\n",
        "original_path = os.path.join(segmentation_path, 'original')\n",
        "real_data_path = os.path.join(original_path, 'real')\n",
        "# real_data_path = '/Volumes/BOOTCAMP/Users/eopok/Desktop/Sentinel/2022'\n",
        "mask_data_path = os.path.join(original_path, 'mask')\n",
        "# divided images\n",
        "divided_data_path = os.path.join(segmentation_path, 'divided')\n",
        "real_divided_data_path = os.path.join(divided_data_path, 'real')\n",
        "mask_divided_data_path = os.path.join(divided_data_path, 'mask')\n",
        "#\n",
        "final_data_path = os.path.join(segmentation_path, 'final')\n",
        "real_final_data_path = os.path.join(final_data_path, 'real')\n",
        "mask_final_data_path = os.path.join(final_data_path, 'mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0bfafa6",
      "metadata": {
        "id": "e0bfafa6"
      },
      "outputs": [],
      "source": [
        "def create_dir_if_not_exists(path):\n",
        "    if os.path.exists(path):\n",
        "        return\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284dd0ed",
      "metadata": {
        "id": "284dd0ed"
      },
      "outputs": [],
      "source": [
        "create_dir_if_not_exists(data_path)\n",
        "create_dir_if_not_exists(segmentation_path)\n",
        "create_dir_if_not_exists(original_path)\n",
        "create_dir_if_not_exists(real_data_path)\n",
        "create_dir_if_not_exists(mask_data_path)\n",
        "print(f\"New directory created: {data_path}\")\n",
        "print(f\"New directory created: {segmentation_path}\")\n",
        "print(f\"New directory created: {original_path}\")\n",
        "print(f\"New directory created: {real_data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8f8bee",
      "metadata": {},
      "source": [
        "# Create Directories and Download Data\n",
        "Create necessary directories and download satellite images and masks from remote sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b4424b",
      "metadata": {
        "id": "00b4424b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import pathlib\n",
        "\n",
        "\n",
        "def download_file(url, dest_path, chunk_size=1024*1024):\n",
        "    \"\"\"\n",
        "    Download a large file from a URL with a progress bar.\n",
        "    Args:\n",
        "        url (str): File URL.\n",
        "        dest_path (str): Destination file path.\n",
        "        chunk_size (int): Download chunk size in bytes.\n",
        "    \"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    total = int(response.headers.get('content-length', 0))\n",
        "    with open(dest_path, 'wb') as file, tqdm(\n",
        "        desc=f\"Downloading {dest_path}\",\n",
        "        total=total,\n",
        "        unit='B',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in response.iter_content(chunk_size=chunk_size):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)\n",
        "\n",
        "def get_all_files(path, pattern='*', get_full_path=False):\n",
        "    files = list(pathlib.Path(path).glob(pattern))\n",
        "    if get_full_path:\n",
        "        onlyfiles = [os.path.join(path, f.name) for f in files if f.is_file()]\n",
        "    else:\n",
        "        onlyfiles = [f.name for f in files if f.is_file()]\n",
        "    return onlyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75edc758",
      "metadata": {},
      "outputs": [],
      "source": [
        "geotiff_image_path = os.path.join(real_data_path, 'sentinel_2024-0000035328-0000023552_harmonized.tif')\n",
        "geotiff_mask_path = os.path.join(mask_data_path, 'sentinel_2024-0000035328-0000023552_harmonized.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed14aa3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed14aa3c",
        "outputId": "34f480c7-4c94-4a5e-8dc8-d927ba41f445"
      },
      "outputs": [],
      "source": [
        "# Download the GeoTIFF image and mask if they do not exist\n",
        "if not os.path.exists(geotiff_image_path):\n",
        "   download_file('https://sco-training.s3.us-east-2.amazonaws.com/sentinel_2024-0000035328-0000023552_harmonized.tif', geotiff_image_path)\n",
        "print(f\"Downloaded GeoTIFF image to: {geotiff_image_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58a4cdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58a4cdd",
        "outputId": "2971ce3f-9004-4a36-bfe4-b5b9f581e7b4"
      },
      "outputs": [],
      "source": [
        "# Download the GeoTIFF image and mask if they do not exist\n",
        "if not os.path.exists(geotiff_image_path):\n",
        "   download_file('https://sco-training.s3.us-east-2.amazonaws.com/sentinel_2024-0000035328-0000023552_harmonized.png', geotiff_mask_path)\n",
        "print(f\"Downloaded mask image to: {geotiff_mask_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d0b12b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display Sentinel satellite image (RGB) and multiclass mask side by side\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_satellite_and_mask(\n",
        "    geotiff_path,\n",
        "    mask_path,\n",
        "    rgb_bands=(2, 1, 0),\n",
        "    color_encoding=None,\n",
        "    rgb_divisor=3000.0,\n",
        "    plotsize=(10, 5)\n",
        "):\n",
        "    \"\"\"\n",
        "    Display Sentinel satellite image as RGB (normalized) and multiclass mask side by side.\n",
        "\n",
        "    Args:\n",
        "        geotiff_path (str): Path to the harmonized .tif file.\n",
        "        mask_path (str): Path to the harmonized .png mask file.\n",
        "        rgb_bands (tuple): Indices for RGB bands in the image.\n",
        "        color_encoding (dict): Mapping of class values to RGB colors.\n",
        "        rgb_divisor (float): Value to normalize image bands.\n",
        "        plotsize (tuple): Size of the matplotlib figure.\n",
        "    \"\"\"\n",
        "    # Load satellite image\n",
        "    from osgeo import gdal\n",
        "    ds = gdal.Open(geotiff_path)\n",
        "    img = np.zeros((ds.RasterYSize, ds.RasterXSize, ds.RasterCount), dtype=np.float32)\n",
        "    for i in range(ds.RasterCount):\n",
        "        img[..., i] = ds.GetRasterBand(i + 1).ReadAsArray()\n",
        "    ds = None\n",
        "\n",
        "    # Prepare RGB image\n",
        "    r, g, b = rgb_bands\n",
        "    rgb = img[..., [r, g, b]] / rgb_divisor\n",
        "    rgb = np.clip(rgb, 0, 1)\n",
        "    rgb_img = (rgb * 255).astype(np.uint8)\n",
        "    rgb_pil = Image.fromarray(rgb_img)\n",
        "\n",
        "    # Load mask\n",
        "    mask = Image.open(mask_path).convert('L')\n",
        "    mask_np = np.array(mask)\n",
        "\n",
        "    # Encode mask colors\n",
        "    if color_encoding is None:\n",
        "        color_encoding = {2: [180, 96, 0], 1: [251, 72, 196], 0: [0, 0, 0]}\n",
        "    mask_rgb = np.zeros((*mask_np.shape, 3), dtype=np.uint8)\n",
        "    for k, v in color_encoding.items():\n",
        "        mask_rgb[mask_np == k] = v\n",
        "    mask_pil = Image.fromarray(mask_rgb)\n",
        "\n",
        "    # Plot side by side\n",
        "    fig, axs = plt.subplots(1, 2, figsize=plotsize)\n",
        "    axs[0].imshow(rgb_pil)\n",
        "    axs[0].set_title(\"Sentinel RGB\")\n",
        "    axs[0].axis('off')\n",
        "    axs[1].imshow(mask_pil)\n",
        "    axs[1].set_title(\"Multiclass Mask\")\n",
        "    axs[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3adba4fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "color_encoding = {2: [180, 96, 0],  # Stream\n",
        "                      1: [251, 72, 196],  # Open Mine\n",
        "                      0: [0, 0, 0]}  # No data\n",
        "\n",
        "display_satellite_and_mask(\n",
        "    geotiff_path=geotiff_image_path,\n",
        "    mask_path=geotiff_mask_path,\n",
        "    rgb_bands=(2, 1, 0),\n",
        "    color_encoding=color_encoding,\n",
        "    plotsize=(12, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feaf5360",
      "metadata": {
        "id": "feaf5360"
      },
      "outputs": [],
      "source": [
        "# stores the path of an image and a mask pair\n",
        "class DataLabelPair:\n",
        "    def __init__(self, data_real_path, label_path):\n",
        "        self.data_real_path = data_real_path\n",
        "        self.label_path = label_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad77ba1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bad77ba1",
        "outputId": "ca7c08bc-d086-4b21-870a-71b355d53c02"
      },
      "outputs": [],
      "source": [
        "#Gets all mask files in the mask folder\n",
        "original_mask_images_path = get_all_files(real_data_path, '*.tif')\n",
        "print('Total files', len(original_mask_images_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d7b53c",
      "metadata": {
        "id": "20d7b53c"
      },
      "outputs": [],
      "source": [
        "images_original = []\n",
        "for path in original_mask_images_path:\n",
        "    image = DataLabelPair(os.path.join(real_data_path, path),\n",
        "                          os.path.join(mask_data_path, path).replace('.tif', '.png'))\n",
        "    images_original.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a45013",
      "metadata": {
        "id": "98a45013"
      },
      "outputs": [],
      "source": [
        "# Specify patch size and strides\n",
        "strides = 224, 224\n",
        "max_grid_size = 224, 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1592c3a9",
      "metadata": {
        "id": "1592c3a9"
      },
      "outputs": [],
      "source": [
        "def get_geoTiff_datatype(geoTiff):\n",
        "    \"\"\"\n",
        "    Get the GDAL data type of a GeoTIFF dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "\n",
        "    Returns:\n",
        "    - int: GDAL data type of the GeoTIFF dataset.\n",
        "\n",
        "    \"\"\"\n",
        "    band = geoTiff.GetRasterBand(1)\n",
        "    return band.DataType\n",
        "\n",
        "\n",
        "def get_geoTiff_numpy_datatype(geoTiff):\n",
        "    \"\"\"\n",
        "    Get the NumPy data type string of a GeoTIFF dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "\n",
        "    Returns:\n",
        "    - str: NumPy data type string of the GeoTIFF dataset.\n",
        "\n",
        "    \"\"\"\n",
        "    gt_dtype = get_geoTiff_datatype(geoTiff)\n",
        "    gdal_to_numpy_datatype = {\n",
        "        gdal.GDT_Byte: 'uint8',\n",
        "        gdal.GDT_UInt16: 'uint16',\n",
        "        gdal.GDT_Int16: 'int16',\n",
        "        gdal.GDT_UInt32: 'uint32',\n",
        "        gdal.GDT_Int32: 'int32',\n",
        "        gdal.GDT_Float32: 'float32',\n",
        "        gdal.GDT_Float64: 'float64'\n",
        "    }\n",
        "    numpy_datatype = gdal_to_numpy_datatype.get(gt_dtype, None)\n",
        "    return numpy_datatype\n",
        "\n",
        "\n",
        "def crop_geoTiff(geoTiff, left, top, right, bottom, dtype=None):\n",
        "    \"\"\"\n",
        "    Crop a GeoTIFF array to the specified region.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "    - left (int): Left coordinate of the crop region.\n",
        "    - top (int): Top coordinate of the crop region.\n",
        "    - right (int): Right coordinate of the crop region.\n",
        "    - bottom (int): Bottom coordinate of the crop region.\n",
        "    - dtype (str or None, optional): Desired data type of the output array.\n",
        "    If set to None, the data type is inferred from the band. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    - output (numpy.ndarray): Cropped array with dimensions (height, width, bands).\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the crop dimensions exceed the size of the GeoTIFF.\n",
        "    \"\"\"\n",
        "    if (int(right) > geoTiff.RasterXSize) or (int(bottom) > geoTiff.RasterYSize):\n",
        "        # print(right, bottom)\n",
        "        # print(geoTiff.RasterXSize, geoTiff.RasterYSize)\n",
        "        raise ValueError('Crop dimensions exceed the size of the GeoTIFF.')\n",
        "    if dtype is None:\n",
        "        dtype = get_geoTiff_numpy_datatype(geoTiff)\n",
        "    width = abs(right - left)\n",
        "    height = abs(top - bottom)\n",
        "    output = np.zeros(\n",
        "        (int(height), int(width), geoTiff.RasterCount), dtype)\n",
        "    # bands = [None] * geoTiff.RasterCount\n",
        "    for x in range(geoTiff.RasterCount):\n",
        "        band = geoTiff.GetRasterBand(x + 1).ReadAsArray(left, top,\n",
        "                                                        int(width), int(height))\n",
        "        output[..., x] = band\n",
        "    return output\n",
        "\n",
        "\n",
        "def read_geoTiff_bands(geoTiff, bands=None, bbox=None, dtype='uint16'):\n",
        "    width = geoTiff.RasterXSize\n",
        "    height = geoTiff.RasterYSize\n",
        "    if bbox == None:\n",
        "       bbox = (0, width, 0, height)\n",
        "    left, right, top, bottom = bbox\n",
        "    bb_width = right - left\n",
        "    bb_height = bottom - top\n",
        "    band_list = []\n",
        "    if bands != None:\n",
        "        for val in bands:\n",
        "            band = geoTiff.GetRasterBand(val).ReadAsArray(left, top,\n",
        "                                                          int(bb_width), int(bb_height))\n",
        "            band_list.append(band)\n",
        "    else:\n",
        "        for x in range(geoTiff.RasterCount):\n",
        "            band = geoTiff.GetRasterBand(x + 1).ReadAsArray(left, top,\n",
        "                                                            int(bb_width), int(bb_height))\n",
        "            band_list.append(band)\n",
        "    output = np.zeros(\n",
        "        (int(bb_height), int(bb_width), len(band_list)), dtype)\n",
        "    for x in range(len(band_list)):\n",
        "        output[..., x] = band_list[x]\n",
        "    return output\n",
        "\n",
        "\n",
        "def read_image(path, color_space=None):\n",
        "    if color_space is None:\n",
        "        img = Image.open(path)\n",
        "    else:\n",
        "        img = Image.open(path).convert(color_space)\n",
        "    return img\n",
        "\n",
        "\n",
        "def split_geoTiff_image(geoTiff, max_grid_size, strides, dtype = 'uint16'):\n",
        "    parts = []\n",
        "    width, height = geoTiff.RasterXSize, geoTiff.RasterYSize\n",
        "    left = 0\n",
        "    top = 0\n",
        "    stride_width, stride_height = strides\n",
        "    max_grid_width, max_grid_height = max_grid_size\n",
        "    total_grids = np.ceil(height / stride_width) * np.ceil(width / stride_height)\n",
        "    for r in range(0, height, stride_height):\n",
        "        for c in range(0, width, stride_width):\n",
        "            left, top = c, r\n",
        "            right, bottom = min(\n",
        "                    c + max_grid_width, width), min(r + max_grid_height,height)\n",
        "            grid = crop_geoTiff(\n",
        "                    geoTiff, left, top, right, bottom, dtype)\n",
        "            # part = gu.crop_geoTiff(geoTiff, left, top, right, bottom)\n",
        "            parts.append(grid)\n",
        "    return parts\n",
        "\n",
        "\n",
        "def split_image(image, max_grid_size, strides):\n",
        "    width, height = image.size\n",
        "    left = 0\n",
        "    top = 0\n",
        "    stride_width, stride_height = strides\n",
        "    max_grid_width, max_grid_height = max_grid_size\n",
        "\n",
        "    for r in range(0, height, stride_height):\n",
        "        for c in range(0, width, stride_width):\n",
        "            left, top = c, r\n",
        "            right, bottom = min(c + max_grid_width, width), min(r + max_grid_height, height)\n",
        "            grid = image.crop((left, top, right, bottom))\n",
        "            yield grid  # Yield the grid as a generator\n",
        "\n",
        "\n",
        "def print_progress(current, total):\n",
        "    # Calculate the percentage of progress\n",
        "    progress = (current / total) * 100\n",
        "    # Print the progress bar\n",
        "    print(\"\\rProgress: [{0:50s}] {1:.1f}%\".format(\n",
        "        '#' * int(progress/2), progress), end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4aea93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f4aea93",
        "outputId": "06af47ed-dc56-4758-941b-c8be150a9eeb"
      },
      "outputs": [],
      "source": [
        "# Create directories for divided data\n",
        "create_dir_if_not_exists(mask_divided_data_path)\n",
        "create_dir_if_not_exists(real_divided_data_path)\n",
        "\n",
        "for i, image_original in enumerate(images_original, 1):\n",
        "    real_image = gdal.Open(image_original.data_real_path)\n",
        "    np_real_image = read_geoTiff_bands(real_image, dtype='float32')\n",
        "    mask_image = read_image(image_original.label_path, 'L')\n",
        "    mask_image = mask_image.resize((real_image.RasterXSize, real_image.RasterYSize), Image.NEAREST)\n",
        "\n",
        "    gt = real_image.GetGeoTransform()\n",
        "\n",
        "    filename = os.path.basename(image_original.data_real_path)\n",
        "    match = re.search(r'(\\d{4})', filename)\n",
        "    if match:\n",
        "        year = int(match.group(1))\n",
        "    else:\n",
        "        year = 2023\n",
        "\n",
        "    # Generate patches first to know their total number\n",
        "    real_patches = list(split_geoTiff_image(real_image, max_grid_size, strides, 'float32'))\n",
        "    mask_patches = list(split_image(mask_image, max_grid_size, strides))\n",
        "\n",
        "    grid_h = max((np_real_image.shape[1] - max_grid_size[0]) // strides[0] + 1, 1)\n",
        "    grid_w = max((np_real_image.shape[2] - max_grid_size[1]) // strides[1] + 1, 1)\n",
        "\n",
        "    for idx, (gt_image_part, mask_image_part) in enumerate(zip(real_patches, mask_patches)):\n",
        "        part_filename = str(uuid.uuid4())\n",
        "\n",
        "        h, w = gt_image_part.shape[1], gt_image_part.shape[2]\n",
        "\n",
        "        patch_row = idx // grid_w\n",
        "        patch_col = idx % grid_w\n",
        "        x_offset = patch_col * strides[1]\n",
        "        y_offset = patch_row * strides[0]\n",
        "\n",
        "        x_center = x_offset + w // 2\n",
        "        y_center = y_offset + h // 2\n",
        "\n",
        "        lon = gt[0] + x_center * gt[1] + y_center * gt[2]\n",
        "        lat = gt[3] + x_center * gt[4] + y_center * gt[5]\n",
        "\n",
        "        temporal_coords = np.array([[year, 1]], dtype=np.float32)\n",
        "        location_coords = np.array([lat, lon], dtype=np.float32)\n",
        "\n",
        "        # ---- CLASS REMAPPING ----\n",
        "        mask_image_part = np.array(mask_image_part)\n",
        "        mask_image_part = mask_image_part.copy()\n",
        "        mask_image_part[np.isin(mask_image_part, [1, 2])] = 1\n",
        "        mask_image_part[mask_image_part == 3] = 2\n",
        "\n",
        "        np.savez(\n",
        "            os.path.join(real_divided_data_path, part_filename + '.npz'),\n",
        "            array1=gt_image_part,\n",
        "            temporal_coords=temporal_coords,\n",
        "            location_coords=location_coords\n",
        "        )\n",
        "        # Save the mask as npz\n",
        "        np.savez(\n",
        "            os.path.join(mask_divided_data_path, part_filename + '.npz'),\n",
        "            mask=mask_image_part\n",
        "        )\n",
        "        #mask_image_part.save(os.path.join(mask_divided_data_path, part_filename + '.png'))\n",
        "\n",
        "    print_progress(i, len(images_original))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3ef31f",
      "metadata": {},
      "source": [
        "# Patch and Encode Images and Masks\n",
        "Split large images and masks into smaller patches, encode them, and save as NPZ files for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409e9775",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "409e9775",
        "outputId": "75841bdd-ff44-44f0-d9fc-7eb22455a0cf"
      },
      "outputs": [],
      "source": [
        "#Images that do not contain any information is deleted from storage.\n",
        "divided_images_path = get_all_files(mask_divided_data_path)\n",
        "len(divided_images_path)\n",
        "print('Total patches:', len(divided_images_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d081647",
      "metadata": {
        "id": "1d081647"
      },
      "outputs": [],
      "source": [
        "images_divided = []\n",
        "for path in divided_images_path:\n",
        "    image = DataLabelPair(os.path.join(real_divided_data_path, path),\n",
        "                          os.path.join(mask_divided_data_path, path))\n",
        "    images_divided.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0627f09d",
      "metadata": {
        "id": "0627f09d"
      },
      "outputs": [],
      "source": [
        "def load_numpy_file(path):\n",
        "    loaded = np.load(path, allow_pickle=True)\n",
        "    return loaded['array1']\n",
        "\n",
        "\n",
        "def display_np_geoTiff(np_geoTiff, rgb_bands, max = None):\n",
        "    r, g, b = rgb_bands\n",
        "    red_band = np_geoTiff[:, :, r]\n",
        "    green_band = np_geoTiff[:, :, g]\n",
        "    blue_band = np_geoTiff[:, :, b]\n",
        "    shape = np_geoTiff.shape\n",
        "    # max = np_geoTiff.max()\n",
        "    # np_rgb_image = np_geoTiff[:, :, 0:3][:, :, ::-1]\n",
        "    rgbOutput = np.zeros((shape[0], shape[1], 3), dtype=np_geoTiff.dtype)\n",
        "    rgbOutput[..., 0] = red_band\n",
        "    rgbOutput[..., 1] = green_band\n",
        "    rgbOutput[..., 2] = blue_band\n",
        "    if max is None:\n",
        "       max = rgbOutput.max()\n",
        "    if max == 0:\n",
        "       max = 1\n",
        "    rgbOutput = (rgbOutput / max) * 255\n",
        "    im = Image.fromarray(np.array(rgbOutput, dtype=np.uint8))\n",
        "    return im\n",
        "\n",
        "def display_legend(np_image, color_encoding):\n",
        "    flat_gh_im = np_image.reshape(-1, 1)\n",
        "    #\n",
        "    new_gh_im = [None] * flat_gh_im.shape[0]\n",
        "    for x in range(flat_gh_im.shape[0]):\n",
        "        new_gh_im[x] = color_encoding.get(flat_gh_im[x][0], [0, 0, 0])\n",
        "    #\n",
        "    new_gh_im = np.array(new_gh_im).reshape(\n",
        "        np_image.shape[0], np_image.shape[1], 3)\n",
        "    enc_im = Image.fromarray(np.array(new_gh_im, dtype=np.uint8))\n",
        "    return enc_im\n",
        "\n",
        "def overlay_mask(original_image, mask_image):\n",
        "    # Open the image and mask\n",
        "    image = original_image.convert('RGBA')\n",
        "    mask = mask_image.convert('RGBA')\n",
        "\n",
        "    # Make pixel value [0, 0, 0] transparent in the mask\n",
        "    mask_data = mask.getdata()\n",
        "    new_mask_data = []\n",
        "    for item in mask_data:\n",
        "        if item[:3] == (0, 0, 0):\n",
        "            # Set transparency for [0, 0, 0]\n",
        "            new_mask_data.append((0, 0, 0, 0))\n",
        "        else:\n",
        "            new_mask_data.append(item)\n",
        "    mask.putdata(new_mask_data)\n",
        "\n",
        "    # Overlay the mask on the image\n",
        "    overlaid = Image.alpha_composite(image, mask)\n",
        "\n",
        "    # Save the overlaid image\n",
        "    return overlaid\n",
        "\n",
        "def display_images(image_dict, grid):\n",
        "    if not isinstance(image_dict, dict):\n",
        "        raise ValueError(\"The 'image_dict' parameter must be a dictionary.\")\n",
        "    rows, cols = grid\n",
        "    num_images = len(image_dict)\n",
        "\n",
        "    if rows is None and cols is None:\n",
        "        rows = int(num_images ** 0.5)\n",
        "        cols = int(num_images ** 0.5)\n",
        "    elif rows is None:\n",
        "        rows = (num_images + cols - 1) // cols\n",
        "    elif cols is None:\n",
        "        cols = (num_images + rows - 1) // rows\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(12, 8))\n",
        "\n",
        "    labels = list(image_dict.keys())\n",
        "    images = list(image_dict.values())\n",
        "\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        if i < num_images:\n",
        "            ax.imshow(images[i])\n",
        "            ax.axis('off')\n",
        "            ax.set_title(labels[i])\n",
        "        else:\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfc2660",
      "metadata": {
        "id": "fcfc2660"
      },
      "outputs": [],
      "source": [
        "# rgb color encoding for mask.\n",
        "color_encoding = {2: [180, 96, 0],  # Stream\n",
        "                      1: [251, 72, 196],  # Open Mine\n",
        "                      0: [0, 0, 0]}  # No data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e17510e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "0e17510e",
        "outputId": "136271f4-ff17-4219-b25d-0d1703f6d36a"
      },
      "outputs": [],
      "source": [
        "#20  12\n",
        "import random\n",
        "indx = random.randint(0, len(divided_images_path))\n",
        "np_gt = load_numpy_file(images_divided[indx].data_real_path)\n",
        "real_im = display_np_geoTiff(np_gt, (2, 1, 0))\n",
        "with np.load(images_divided[indx].label_path) as np_mask:\n",
        "                mask_array = np_mask[np_mask.files[0]].astype(np.uint8)\n",
        "mask = display_legend(mask_array, color_encoding)\n",
        "display_images({'Satellite Image': real_im, 'Mask': mask,\n",
        "                'Overlay': overlay_mask(real_im, mask)}, (1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4260cc83",
      "metadata": {
        "id": "4260cc83"
      },
      "outputs": [],
      "source": [
        "# Splits dataset into training, validation and test sets.\n",
        "def train_val_test_split(val_per, test_per, input_data, labels=None):\n",
        "    if labels is not None and len(input_data) != len(labels):\n",
        "        raise Exception(\"input data and label length mismatch\")\n",
        "    data_len = len(input_data)\n",
        "    val_len = int(data_len * (val_per / 100))\n",
        "    test_len = int(data_len * (test_per / 100))\n",
        "    x_val = input_data[0: val_len]\n",
        "    x_test = input_data[val_len: val_len + test_len]\n",
        "    x_train = input_data[val_len + test_len: data_len]\n",
        "    if labels is not None:\n",
        "        y_val = labels[0: val_len]\n",
        "        y_test = labels[val_len: val_len + test_len]\n",
        "        y_train = labels[val_len + test_len: data_len]\n",
        "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
        "    else:\n",
        "        return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57208ac4",
      "metadata": {},
      "source": [
        "# Split Dataset into Train, Validation, and Test Sets\n",
        "Divide the processed image and mask pairs into training, validation, and test sets for model development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089340b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "089340b1",
        "outputId": "3a39e93c-19d2-424c-9136-b648c2ab197e"
      },
      "outputs": [],
      "source": [
        "train_images, val_images, test_images = train_val_test_split(\n",
        "    15, 0, images_divided)\n",
        "print('Train length:', len(train_images))\n",
        "print('Val length:', len(val_images))\n",
        "print('Test length', len(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98620793",
      "metadata": {
        "id": "98620793"
      },
      "outputs": [],
      "source": [
        "#create directories for all training data.\n",
        "training_path = os.path.join(segmentation_path, 'training')\n",
        "create_dir_if_not_exists(training_path)\n",
        "#train\n",
        "train_path = os.path.join(training_path, 'train')\n",
        "create_dir_if_not_exists(train_path)\n",
        "train_real_path = os.path.join(train_path, 'real')\n",
        "create_dir_if_not_exists(train_real_path)\n",
        "train_mask_path = os.path.join(train_path, 'mask')\n",
        "create_dir_if_not_exists(train_mask_path)\n",
        "#val\n",
        "val_path = os.path.join(training_path, 'val')\n",
        "create_dir_if_not_exists(val_path)\n",
        "val_real_path = os.path.join(val_path, 'real')\n",
        "create_dir_if_not_exists(val_real_path)\n",
        "val_mask_path = os.path.join(val_path, 'mask')\n",
        "create_dir_if_not_exists(val_mask_path)\n",
        "#test\n",
        "test_path = os.path.join(training_path, 'test')\n",
        "create_dir_if_not_exists(test_path)\n",
        "test_real_path = os.path.join(test_path, 'real')\n",
        "create_dir_if_not_exists(test_real_path)\n",
        "test_mask_path = os.path.join(test_path, 'mask')\n",
        "create_dir_if_not_exists(test_mask_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93aeaf68",
      "metadata": {},
      "source": [
        "# Organize Data into Train, Validation, and Test Folders\n",
        "Move the split data into dedicated directories for training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e9c463",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07e9c463",
        "outputId": "33451f80-8431-42cd-efb0-6e828050de20"
      },
      "outputs": [],
      "source": [
        "# copy training images to training folder\n",
        "i = 0\n",
        "for image in train_images:\n",
        "    shutil.move(image.data_real_path, os.path.join(\n",
        "        train_real_path, os.path.basename(image.data_real_path)))\n",
        "    shutil.move(image.label_path, os.path.join(\n",
        "        train_mask_path, os.path.basename(image.label_path)))\n",
        "    i += 1\n",
        "    print_progress(i, len(train_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1e90d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec1e90d0",
        "outputId": "5ff28d8d-1781-44cc-8ced-2a33e6dc152a"
      },
      "outputs": [],
      "source": [
        "# copy training images to training folder\n",
        "i = 0\n",
        "for image in val_images:\n",
        "    shutil.move(image.data_real_path, os.path.join(\n",
        "        val_real_path, os.path.basename(image.data_real_path)))\n",
        "    shutil.move(image.label_path, os.path.join(\n",
        "        val_mask_path, os.path.basename(image.label_path)))\n",
        "    i += 1\n",
        "    print_progress(i, len(val_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b4a6e7",
      "metadata": {
        "id": "85b4a6e7"
      },
      "outputs": [],
      "source": [
        "def delete_file(file_path):\n",
        "    \"\"\"\n",
        "    Deletes the specified file if it exists.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): Path to the file to delete.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "\n",
        "    Raises:\n",
        "    - FileNotFoundError: If the file does not exist.\n",
        "    - OSError: If there is an error during deletion.\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        # print(f\"Deleted file: {file_path}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bcf522",
      "metadata": {
        "id": "21bcf522"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os, sys\n",
        "\n",
        "# --- helpers -----------------------------------------------------------------\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, np.ndarray):\n",
        "        value = value.tobytes()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    if not isinstance(value, (list, tuple)):\n",
        "        value = [value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    if isinstance(value, np.ndarray):\n",
        "        value = value.flatten().tolist()\n",
        "    elif isinstance(value, (list, tuple)):\n",
        "        value = list(value)\n",
        "    else:\n",
        "        value = [value]\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "\n",
        "def write_tfrecords(image_paths, mask_paths, tfrecord_filename):\n",
        "    \"\"\"\n",
        "    Serialise paired .npz images & masks into a TFRecord, including temporal and location coords.\n",
        "    \"\"\"\n",
        "    assert len(image_paths) == len(mask_paths), \"image_paths and mask_paths length mismatch\"\n",
        "    total = len(image_paths)\n",
        "    #options = tf.io.TFRecordOptions(compression_type=\"GZIP\")   # or \"ZLIB\"\n",
        "    with tf.io.TFRecordWriter(tfrecord_filename) as writer:\n",
        "        for i, (img_p, msk_p) in enumerate(zip(image_paths, mask_paths), 1):\n",
        "            # load image .npz (expects keys: array1, temporal_coords, location_coords)\n",
        "            with np.load(img_p) as img_npz:\n",
        "                img_array = img_npz['array1'].astype(np.float32)\n",
        "                temporal_coords = img_npz['temporal_coords'].astype(np.float32).flatten()   # shape (2,)\n",
        "                location_coords = img_npz['location_coords'].astype(np.float32).flatten()   # shape (2,)\n",
        "\n",
        "            with np.load(msk_p) as msk_npz:\n",
        "                mask_array = msk_npz[msk_npz.files[0]].astype(np.uint8)\n",
        "\n",
        "            # (h, w, c) or (c, h, w)?\n",
        "            if img_array.shape[0] <= 10:  # (bands, H, W)\n",
        "                c, h, w = img_array.shape\n",
        "                img_array = np.transpose(img_array, (1, 2, 0))  # (H, W, C) for TF\n",
        "            else:\n",
        "                h, w, c = img_array.shape\n",
        "\n",
        "            # build Example\n",
        "            example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                \"image_raw\": _bytes_feature(img_array),\n",
        "                \"mask_raw\":  _bytes_feature(mask_array),\n",
        "                \"height\":    _int64_feature(h),\n",
        "                \"width\":     _int64_feature(w),\n",
        "                \"channels\":  _int64_feature(c),\n",
        "                \"image_name\": _bytes_feature(os.path.basename(img_p).encode()),\n",
        "                \"mask_name\":  _bytes_feature(os.path.basename(msk_p).encode()),\n",
        "                \"temporal_coords\": _float_feature(temporal_coords),    # [year, doy]\n",
        "                \"location_coords\": _float_feature(location_coords),    # [lat, lon]\n",
        "            }))\n",
        "            writer.write(example.SerializeToString())\n",
        "\n",
        "            if i % 500 == 0:\n",
        "               writer.flush()\n",
        "            # progress bar\n",
        "            pct = int(i * 100 / total)\n",
        "            sys.stdout.write(f\"\\r▶  {pct:3d}%\")\n",
        "            sys.stdout.flush()\n",
        "            delete_file(img_p)\n",
        "            delete_file(msk_p)\n",
        "\n",
        "    sys.stdout.write(\"\\r✔  100%  TFRecord written → {}\\n\".format(tfrecord_filename))\n",
        "    sys.stdout.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc19416",
      "metadata": {},
      "source": [
        "# Export Data to TFRecord Format\n",
        "Convert the processed image and mask pairs into TFRecord files for efficient training in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a7886f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a7886f",
        "outputId": "a90ff5eb-c9d0-4b06-af87-a65dcbf04611"
      },
      "outputs": [],
      "source": [
        "train_img_paths = sorted(get_all_files(train_real_path, '*.npz', True))\n",
        "train_mask_paths = sorted(get_all_files(train_mask_path, '*.npz', True))\n",
        "print('real:',len(train_img_paths), 'mask:', len(train_mask_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e645af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3e645af",
        "outputId": "e7715c16-a677-4c26-b4b1-87814975e2b1"
      },
      "outputs": [],
      "source": [
        "write_tfrecords(train_img_paths, train_mask_paths, \"/content/drive/MyDrive/SCO_training/ssm_footprint_train.tfrecord\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d617af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25d617af",
        "outputId": "bf8e6873-68ca-4553-b83a-0750ac3a4a76"
      },
      "outputs": [],
      "source": [
        "val_img_paths = sorted(get_all_files(val_real_path, '*.npz', True))\n",
        "val_mask_paths = sorted(get_all_files(val_mask_path, '*.npz', True))\n",
        "print('real:',len(val_img_paths), 'mask:', len(val_mask_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ee74f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ee74f8",
        "outputId": "747cc5a5-f982-415f-93bf-90a6619c1a1d"
      },
      "outputs": [],
      "source": [
        "write_tfrecords(val_img_paths, val_mask_paths, \"/content/drive/MyDrive/SCO_training/ssm_footprint_val.tfrecord\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (ml-env)",
      "language": "python",
      "name": "ml-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
