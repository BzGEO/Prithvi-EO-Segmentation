{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2cd75c76",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easare377/Prithvi-EO-Segmentation/blob/main/Training_and_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9410196",
      "metadata": {
        "id": "e9410196"
      },
      "source": [
        "Import essential libraries for data manipulation, model building, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LNW7606TYaOg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LNW7606TYaOg",
        "outputId": "b42590a8-7e7b-43db-d1c8-2d963dcb7ecf"
      },
      "outputs": [],
      "source": [
        "!pip install terratorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KbtyiBLFtU5v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbtyiBLFtU5v",
        "outputId": "dc7c1925-a6aa-40ff-8169-7136b8656b04"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d99dd89",
      "metadata": {
        "id": "8d99dd89"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12dee3d3",
      "metadata": {
        "id": "12dee3d3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_file(url, dest_path, chunk_size=1024*1024):\n",
        "    \"\"\"\n",
        "    Download a large file from a URL with a progress bar.\n",
        "    Args:\n",
        "        url (str): File URL.\n",
        "        dest_path (str): Destination file path.\n",
        "        chunk_size (int): Download chunk size in bytes.\n",
        "    \"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    total = int(response.headers.get('content-length', 0))\n",
        "    with open(dest_path, 'wb') as file, tqdm(\n",
        "        desc=f\"Downloading {dest_path}\",\n",
        "        total=total,\n",
        "        unit='B',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in response.iter_content(chunk_size=chunk_size):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HKLb2lGlH3YJ",
      "metadata": {
        "id": "HKLb2lGlH3YJ"
      },
      "outputs": [],
      "source": [
        "train_file_path = '/content/drive/MyDrive/SCO_training/ssm_footprint_train.tfrecord'\n",
        "val_file_path = '/content/drive/MyDrive/SCO_training/ssm_footprint_val.tfrecord'\n",
        "# Create the directory if it doesn't exist\n",
        "train_dir = os.path.dirname(train_file_path)\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "val_dir = os.path.dirname(val_file_path)\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a30cd74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a30cd74",
        "outputId": "979733ce-173f-4d51-bffd-64154799232a"
      },
      "outputs": [],
      "source": [
        "\n",
        "#download_file(\"https://sco-training.s3.us-east-2.amazonaws.com/ssm_footprint_train.tfrecord\", train_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26925135",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26925135",
        "outputId": "f1fe2569-3e73-43d7-b05f-85eb52120d72"
      },
      "outputs": [],
      "source": [
        "# Create the directory if it doesn't exist\n",
        "\n",
        "#download_file(\"https://sco-training.s3.us-east-2.amazonaws.com/ssm_footprint_val.tfrecord\", val_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b5d741",
      "metadata": {
        "id": "30b5d741"
      },
      "outputs": [],
      "source": [
        "def zero_pad_array(input_array, new_shape):\n",
        "    \"\"\"\n",
        "    Zero-pad the input_array to the specified new_shape.\n",
        "    Args:\n",
        "        input_array (numpy.ndarray): Input array of shape (height, width, ...).\n",
        "        new_shape (tuple): Desired new shape (new_height, new_width, ...).\n",
        "    Returns:\n",
        "        numpy.ndarray: Zero-padded array of shape (new_height, new_width, ...).\n",
        "    \"\"\"\n",
        "    h, w = input_array.shape[:2]\n",
        "    new_h, new_w = new_shape[:2]\n",
        "    pad_h = max(new_h - h, 0)\n",
        "    pad_w = max(new_w - w, 0)\n",
        "    pad_values = [(0, pad_h), (0, pad_w)]\n",
        "    pad_values += [(0, 0)] * (input_array.ndim - 2)\n",
        "    return np.pad(input_array, pad_values, mode='constant', constant_values=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3392d8fe",
      "metadata": {
        "id": "3392d8fe"
      },
      "source": [
        "Implement a PyTorch Dataset for loading images and masks from NPZ files, including normalization and padding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c60285",
      "metadata": {
        "id": "97c60285"
      },
      "source": [
        "\n",
        "Implement a PyTorch Dataset for loading images and masks from TFRecord files, including normalization and padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a20e06e2",
      "metadata": {
        "id": "a20e06e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def zero_pad_array(arr, target_hw):\n",
        "    th, tw = target_hw\n",
        "    h, w = arr.shape[:2]\n",
        "    pad_h = max(th - h, 0)\n",
        "    pad_w = max(tw - w, 0)\n",
        "    pad = ((pad_h // 2, pad_h - pad_h // 2),\n",
        "           (pad_w // 2, pad_w - pad_w // 2))\n",
        "    if arr.ndim == 3: pad += ((0, 0),)\n",
        "    return np.pad(arr, pad, mode='constant')\n",
        "\n",
        "class MineFootprintTFRecordDataset(Dataset):\n",
        "    MEAN = np.array([1635.8452, 1584.4594, 1456.8425, 2926.6663, 2135.001, 1352.7313], dtype=np.float32)\n",
        "    STD  = np.array([884.3994, 815.4016, 839.0293, 1055.6382, 751.4628, 628.5323], dtype=np.float32)\n",
        "\n",
        "    _feature_desc = {\n",
        "        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"mask_raw\":  tf.io.FixedLenFeature([], tf.string),\n",
        "        \"height\":    tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"width\":     tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"channels\":  tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"temporal_coords\": tf.io.FixedLenFeature([2], tf.float32),\n",
        "        \"location_coords\": tf.io.FixedLenFeature([2], tf.float32),\n",
        "    }\n",
        "\n",
        "    def __init__(self, tfrecord_file, transform=None, pad_to=(224, 224)):\n",
        "        super().__init__()\n",
        "        self.tfrecord_path = os.fspath(tfrecord_file)\n",
        "        self.transform = transform\n",
        "        self.pad_to = pad_to\n",
        "\n",
        "        # ---- build a list of byte offsets ----------------------------------\n",
        "        self._offsets = self._scan_index()\n",
        "        self._fh = open(self.tfrecord_path, 'rb')\n",
        "\n",
        "    def _scan_index(self):\n",
        "        \"\"\"Return a list with the starting byte of each record.\"\"\"\n",
        "        offsets = []\n",
        "        with open(self.tfrecord_path, 'rb') as f:\n",
        "            pos = 0\n",
        "            while True:\n",
        "                header = f.read(12)\n",
        "                if not header: break\n",
        "                rec_len = struct.unpack('<Q', header[:8])[0]\n",
        "                offsets.append(pos)\n",
        "                pos += 12 + rec_len + 4\n",
        "                f.seek(pos)\n",
        "        return offsets\n",
        "\n",
        "    def _read_record(self, offset):\n",
        "        \"\"\"Seek & return the serialised Example bytes of one record.\"\"\"\n",
        "        self._fh.seek(offset)\n",
        "        header = self._fh.read(12)\n",
        "        rec_len = struct.unpack('<Q', header[:8])[0]\n",
        "        data = self._fh.read(rec_len)\n",
        "        _ = self._fh.read(4)\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._offsets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        serialised = self._read_record(self._offsets[idx])\n",
        "        ex = tf.io.parse_single_example(serialised, self._feature_desc)\n",
        "\n",
        "        h = int(ex[\"height\"])\n",
        "        w = int(ex[\"width\"])\n",
        "        c = int(ex[\"channels\"])\n",
        "\n",
        "        img = np.frombuffer(ex[\"image_raw\"].numpy(), dtype=np.float32).reshape((h, w, c))\n",
        "        msk = np.frombuffer(ex[\"mask_raw\"].numpy(),  dtype=np.uint8).reshape((h, w))\n",
        "\n",
        "        img = np.nan_to_num(img, nan=0.0)\n",
        "        msk = np.nan_to_num(msk.astype(np.float32), nan=0.0).astype(np.uint8)\n",
        "\n",
        "        img = (img - self.MEAN) / self.STD\n",
        "        img = zero_pad_array(img, self.pad_to)\n",
        "        msk = zero_pad_array(msk, self.pad_to)\n",
        "\n",
        "        temporal_coords = ex['temporal_coords'].numpy().astype(np.float32)   # (2,)\n",
        "        location_coords = ex['location_coords'].numpy().astype(np.float32)   # (2,)\n",
        "\n",
        "        temporal_coords = np.expand_dims(temporal_coords, axis=0)            # (1, 2)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img, mask=msk)\n",
        "            img, msk   = augmented[\"image\"], augmented[\"mask\"]\n",
        "        else:\n",
        "            img = torch.from_numpy(img.transpose(2, 0, 1))  # (C,H,W)\n",
        "            msk = torch.from_numpy(msk)\n",
        "\n",
        "        out = {\n",
        "            \"image\": img.float(),\n",
        "            \"temporal_coords\": torch.from_numpy(temporal_coords),\n",
        "            \"location_coords\": torch.from_numpy(location_coords),\n",
        "            \"mask\": msk.long()\n",
        "        }\n",
        "        return out\n",
        "\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            if hasattr(self, '_fh') and not self._fh.closed:\n",
        "                self._fh.close()\n",
        "        except Exception:\n",
        "            pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e60783",
      "metadata": {
        "id": "f9e60783"
      },
      "source": [
        "Set up an Albumentations transformation pipeline for data augmentation during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b98c655",
      "metadata": {
        "id": "7b98c655"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "# Define transformation pipeline\n",
        "transform = A.Compose([\n",
        "    A.RandomRotate90(p=0.7),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9d819cd",
      "metadata": {
        "id": "d9d819cd"
      },
      "source": [
        "# Prepare Training Dataset and DataLoader\n",
        "Initialize the training dataset and DataLoader for batch processing and shuffling."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca41ab3",
      "metadata": {
        "id": "9ca41ab3"
      },
      "source": [
        "# Prepare TFRecord Training Dataset and DataLoader\n",
        "Initialize the TFRecord-based training dataset and DataLoader for batch processing and shuffling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8afbba90",
      "metadata": {
        "id": "8afbba90"
      },
      "outputs": [],
      "source": [
        "train_dataset = MineFootprintTFRecordDataset(train_file_path, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True,drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ef8ea54",
      "metadata": {
        "id": "0ef8ea54"
      },
      "source": [
        "# Define Semantic Segmentation Model\n",
        "Create a semantic segmentation model using the TerraTorch library with a Prithvi EO backbone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tlu1I6kaZSvD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlu1I6kaZSvD",
        "outputId": "8967ddc1-3ff7-4483-e5cf-8da454ccf2a9"
      },
      "outputs": [],
      "source": [
        "from terratorch import BACKBONE_REGISTRY\n",
        "# print just the Prithvi family (any registry)\n",
        "prithvi_backbones = sorted([n for n in BACKBONE_REGISTRY if \"prithvi\" in n])\n",
        "for backbone in prithvi_backbones:\n",
        "    print(f\"{backbone}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2086f22",
      "metadata": {},
      "source": [
        "## Prithvi Backbone Model Versions\n",
        "\n",
        "| Model Name              | Size / Features     | Description                                                                 |\n",
        "|-------------------------|--------------------|-----------------------------------------------------------------------------|\n",
        "| Prithvi-EO-1.0-100M     | 100M parameters    | The original Prithvi-EO model (ViT backbone, 100M params), pretrained on US-only HLS data. |\n",
        "| Prithvi-EO-2.0-100M     | 100M parameters    | Same architecture as 1.0-100M, but pretrained on a larger, global dataset.  |\n",
        "| Prithvi-EO-2.0-300M     | 300M parameters    | Larger model, trained on global HLS data, without temporal/location embeddings. |\n",
        "| Prithvi-EO-2.0-300M-TL  | 300M + Temp/Loc    | Same as above but with temporal and location embeddings.                     |\n",
        "| Prithvi-EO-2.0-600M     | 600M parameters    | Even larger model, trained on global data, without temporal/location embeddings. |\n",
        "| Prithvi-EO-2.0-600M-TL  | 600M + Temp/Loc    | Largest model, with both temporal and location embeddings included.          |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1625c520",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "0918ff02c48d41ee8e58ec08cea81fa1",
            "6db0f68a255b4d91b9d6c203f953226e",
            "82f6b70703d340d194450d0972fdef58",
            "5fd641cbadac4e9391dc0c823afc8324",
            "aa8070fb7ec44578ad9359edbdf5f65b",
            "c7f0a3f130e4423dafac54eef9079a21",
            "84256d738dc84ae7b2223be1c1d04a26",
            "b788b2fe77b04835bce5c2186bf12b8c",
            "d83e70344b6d41f3a7828fbcbf0c5b0c",
            "da97cbf5a1014b4e972bdc2ca435820e",
            "c40aa0e088d5448f9dcbc1c74a3ace7f",
            "4c0b669beea2425cabb248a72bbda84a",
            "2b58049c98c2406fb913e4e505f1a0ca",
            "d54942daf8d0416f831e6bcec4572f6b",
            "f6277bdc3d6e411092f5cb0d1f8be4a3",
            "f3c39a7970f6486cb3de35568cca44cd",
            "fa878a4d378842bcb6ffb857fcec7a22",
            "8e7aeb08233a4151b9a4e88f8dadcff0",
            "dd9de31defc54a6c8864116119a5fca6",
            "5ca7565bdf814bb0a5494cdd2048c795",
            "03660dd3c2434ffa8289ffb452d7d94a",
            "932f4a932f10415d8e3d527f248723e5"
          ]
        },
        "id": "1625c520",
        "outputId": "d4143c9c-c1df-4021-e987-2921e1523ea8"
      },
      "outputs": [],
      "source": [
        "from terratorch.tasks import SemanticSegmentationTask\n",
        "\n",
        "model = SemanticSegmentationTask(\n",
        "    model_factory=\"EncoderDecoderFactory\",\n",
        "    model_args=dict(\n",
        "        backbone=\"terratorch_prithvi_eo_v2_300_tl\",\n",
        "        backbone_pretrained=True,\n",
        "        backbone_img_size=224,\n",
        "        backbone_bands=[\"BLUE\",\"GREEN\",\"RED\",\"NIR_NARROW\",\"SWIR_1\",\"SWIR_2\"],\n",
        "        necks=[{\"name\":\"SelectIndices\", \"indices\":[1, 5,11,17,23]},\n",
        "               {\"name\":\"ReshapeTokensToImage\"}],\n",
        "        decoder=\"FCNDecoder\",\n",
        "        decoder_channels=256,\n",
        "        num_classes=3,\n",
        "        head_dropout=0.1,\n",
        "    ),\n",
        "    freeze_backbone=False,\n",
        "    freeze_decoder=False,\n",
        ")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f26e6eba",
      "metadata": {
        "id": "f26e6eba"
      },
      "source": [
        "# Load Pretrained Model Weights\n",
        "Load pretrained weights into the segmentation model for transfer learning or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ad3687",
      "metadata": {
        "id": "d1ad3687",
        "outputId": "310b930f-47db-4dbe-ed4a-9aa34d29de69"
      },
      "outputs": [],
      "source": [
        "#load pretrained weights\n",
        "#from pathlib import Path\n",
        "#model_save_path  = Path(\"/content/drive/MyDrive/SCO_training/prithvi_state_dict.pt\")\n",
        "#model.load_state_dict(torch.load(model_save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2399c7",
      "metadata": {
        "id": "de2399c7"
      },
      "source": [
        "\n",
        "Display the number of trainable and total parameters in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125a790b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "125a790b",
        "outputId": "93b51db0-1631-44b1-b274-1ab772d799ae"
      },
      "outputs": [],
      "source": [
        "print(\"Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"Total params:\", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea5fc830",
      "metadata": {
        "id": "ea5fc830"
      },
      "source": [
        "# Example Model Forward Pass\n",
        "Demonstrate a forward pass through the model with dummy data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457c9ff8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "457c9ff8",
        "outputId": "ad6824f6-46ff-41f3-a3c3-9fd7c7a9021c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "B = 4\n",
        "temporal_coords = torch.tensor([[2023, 123]] * B, dtype=torch.float32).unsqueeze(1)  # [B, 1, 2], float!\n",
        "location_coords = torch.tensor([[7.12, -1.5]] * B, dtype=torch.float32)              # [B, 2], float!\n",
        "\n",
        "batch = {\n",
        "    \"image\": torch.randn(B, 6, 224, 224),\n",
        "    \"temporal_coords\": temporal_coords,\n",
        "    \"location_coords\": location_coords\n",
        "}\n",
        "\n",
        "output = model(\n",
        "    batch[\"image\"],\n",
        "    temporal_coords=batch[\"temporal_coords\"],\n",
        "    location_coords=batch[\"location_coords\"]\n",
        ")\n",
        "print(output.output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6831a10d",
      "metadata": {
        "id": "6831a10d"
      },
      "source": [
        "# Set Device, Loss Function, and Optimizer\n",
        "Configure the device (CPU/GPU), loss function, and optimizer for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753d8971",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "753d8971",
        "outputId": "17661b6f-16b3-4b29-b50c-5f786e2af7b2"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Define loss and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.5e-5)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1e617f",
      "metadata": {
        "id": "2b1e617f"
      },
      "source": [
        "# Training Loop\n",
        "Implement the training loop for the segmentation model, including loss calculation and model checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a90b007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a90b007",
        "outputId": "9d34c148-6017-4b9b-ff6d-d4ec287299a6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from pathlib import Path\n",
        "from time import time\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "num_epochs = 1\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0          # sum of (batch_loss × batch_size)\n",
        "    seen_samples = 0            # how many samples we’ve seen so far\n",
        "\n",
        "    pbar = tqdm(\n",
        "        enumerate(train_loader, 1),\n",
        "        total=len(train_loader),\n",
        "        desc=f\"Epoch {epoch}/{num_epochs}\",\n",
        "        ncols=120,\n",
        "        unit=\"batch\",\n",
        "        leave=False\n",
        "    )\n",
        "    start_time = time()\n",
        "\n",
        "    for step, batch in pbar:\n",
        "        images =  batch[\"image\"].to(device)\n",
        "        masks = batch['mask'].to(device)\n",
        "        temporal_coords=batch[\"temporal_coords\"].to(device)\n",
        "        location_coords=batch[\"location_coords\"].to(device)\n",
        "        #images, masks = images.to(device), masks.to(device)\n",
        "        bsz = images.size(0)     # current batch size (last batch may be smaller)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs  = model(images, temporal_coords=temporal_coords, location_coords=location_coords)\n",
        "        loss = criterion(outputs.output, masks.long())\n",
        "        #loss = criterion(outputs, masks.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ------------------- running average -------------------\n",
        "        running_loss += loss.item() * bsz   # accumulate weighted loss\n",
        "        seen_samples += bsz\n",
        "        avg_loss_so_far = running_loss / seen_samples\n",
        "        # -------------------------------------------------------\n",
        "\n",
        "        elapsed = time() - start_time\n",
        "        batches_left = len(train_loader) - step\n",
        "        eta = timedelta(seconds=int(elapsed / step * batches_left))\n",
        "        pbar.set_postfix_str(f\"loss: {avg_loss_so_far:.4f} - ETA: {eta}\")\n",
        "\n",
        "    epoch_loss = running_loss / seen_samples\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"\\n📌 Epoch {epoch} completed – Avg Loss: {epoch_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PDE0-bHLeakI",
      "metadata": {
        "id": "PDE0-bHLeakI"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(model.state_dict(), Path(\"/content/drive/MyDrive/SCO_training/prithvi_state_dict.pt\"))\n",
        "print(\"Model saved to /content/drive/MyDrive/SCO_training/prithvi_state_dict.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d44f155",
      "metadata": {
        "id": "8d44f155"
      },
      "source": [
        "# Prediction and Visualization Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7f8408",
      "metadata": {
        "id": "be7f8408"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  colour map  (default is the dict you provided)\n",
        "# ------------------------------------------------------------------ #\n",
        "DEFAULT_ENCODING = {\n",
        "    3: [255, 255,   0],   # yellow\n",
        "    2: [180,  96,   0],   # brown-ish\n",
        "    1: [251,  72, 196],   # magenta\n",
        "    0: [  0,   0,   0],   # black – background\n",
        "}\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  visualisation util\n",
        "# ------------------------------------------------------------------ #\n",
        "def _overlay(rgb, mask, colour_encoding, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Return an RGB image with the segmentation mask blended on top.\n",
        "    `rgb`      : float32, range [0-1], shape (H,W,3)\n",
        "    `mask`     : int/uint8, shape (H,W)\n",
        "    \"\"\"\n",
        "    h, w = mask.shape\n",
        "    colour_arr = np.zeros((h, w, 3), dtype=np.float32)\n",
        "\n",
        "    for cls_id, colour in colour_encoding.items():\n",
        "        colour_arr[mask == cls_id] = np.array(colour, dtype=np.float32) / 255.0\n",
        "\n",
        "    return (1 - alpha) * rgb + alpha * colour_arr\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  main helper\n",
        "# ------------------------------------------------------------------ #\n",
        "def visualise_random_prediction(\n",
        "    model,\n",
        "    dataset: MineFootprintTFRecordDataset,\n",
        "    device=\"cuda\",\n",
        "    colour_encoding: dict[int, list[int]] | None = None,\n",
        "    rgb_divisor: float = 3000.0,\n",
        "    alpha: float = 0.4,\n",
        "):\n",
        "    \"\"\"\n",
        "    • Randomly selects a sample from `dataset`\n",
        "    • Runs `model` in eval mode\n",
        "    • Displays RGB, GT overlay, prediction overlay\n",
        "    \"\"\"\n",
        "    colour_encoding = colour_encoding or DEFAULT_ENCODING\n",
        "    model.eval().to(device)\n",
        "\n",
        "    # -------- pick random sample -----------------------------------\n",
        "    idx   = random.randrange(len(dataset))\n",
        "    batch = dataset[idx]                     # dict with image/coords/mask\n",
        "    print(batch[\"image\"].unsqueeze(0).shape )\n",
        "    img_t = batch[\"image\"].unsqueeze(0).to(device)            # (1,C,H,W)\n",
        "    temp  = batch[\"temporal_coords\"].unsqueeze(0).to(device)               # (1,1,2)\n",
        "    loc   = batch[\"location_coords\"].unsqueeze(0).to(device)  # (1,2)\n",
        "    gt    = batch[\"mask\"].cpu().numpy()                       # (H,W)\n",
        "\n",
        "    # -------- forward pass -----------------------------------------\n",
        "    with torch.no_grad():\n",
        "        out = model(img_t, temporal_coords=temp, location_coords=loc)\n",
        "        logits = out.output if hasattr(out, \"output\") else out\n",
        "        pred   = torch.argmax(logits, dim=1).cpu().numpy()[0]  # (H,W)\n",
        "\n",
        "    # -------- prepare RGB for display ------------------------------\n",
        "    # un-normalise\n",
        "    img_np = batch[\"image\"].cpu().numpy()            # (C,H,W), z-score\n",
        "    img_np = img_np * dataset.STD[:, None, None] + dataset.MEAN[:, None, None]\n",
        "    rgb    = img_np[:3].transpose(1, 2, 0) / rgb_divisor\n",
        "    rgb    = np.clip(rgb, 0.0, 1.0)\n",
        "\n",
        "    # -------- build overlays ---------------------------------------\n",
        "    gt_overlay   = _overlay(rgb, gt,   colour_encoding, alpha)\n",
        "    pred_overlay = _overlay(rgb, pred, colour_encoding, alpha)\n",
        "\n",
        "    # -------- plot --------------------------------------------------\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    titles = [\"RGB\", \"GT overlay\", \"Prediction overlay\"]\n",
        "    imgs   = [rgb, gt_overlay, pred_overlay]\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(imgs, titles), 1):\n",
        "        plt.subplot(1, 3, i)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(title)\n",
        "\n",
        "    plt.suptitle(f\"Random sample #{idx}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a006e4",
      "metadata": {
        "id": "b6a006e4"
      },
      "source": [
        "# Visualize Random Prediction\n",
        "Run the advanced visualization function to display a random sample from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JtALbt9Hcg5V",
      "metadata": {
        "id": "JtALbt9Hcg5V"
      },
      "outputs": [],
      "source": [
        "val_dataset = MineFootprintTFRecordDataset(val_file_path, transform=transform)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71d85a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "f71d85a8",
        "outputId": "b81e0d5e-515c-4c03-a051-6ea53a870fe9"
      },
      "outputs": [],
      "source": [
        "\n",
        "visualise_random_prediction(\n",
        "    model,\n",
        "    dataset=val_dataset,\n",
        "    device=device,\n",
        "    colour_encoding=DEFAULT_ENCODING,  # or your own\n",
        "    rgb_divisor=3000.0,\n",
        "    alpha=0.9\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d81cd993",
      "metadata": {
        "id": "d81cd993"
      },
      "source": [
        "Now, try running the cell to mount Google Drive again."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (ml-env)",
      "language": "python",
      "name": "ml-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03660dd3c2434ffa8289ffb452d7d94a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0918ff02c48d41ee8e58ec08cea81fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db0f68a255b4d91b9d6c203f953226e",
              "IPY_MODEL_82f6b70703d340d194450d0972fdef58",
              "IPY_MODEL_5fd641cbadac4e9391dc0c823afc8324"
            ],
            "layout": "IPY_MODEL_aa8070fb7ec44578ad9359edbdf5f65b"
          }
        },
        "2b58049c98c2406fb913e4e505f1a0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa878a4d378842bcb6ffb857fcec7a22",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7aeb08233a4151b9a4e88f8dadcff0",
            "value": "Prithvi_EO_V2_300M_TL.pt: 100%"
          }
        },
        "4c0b669beea2425cabb248a72bbda84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b58049c98c2406fb913e4e505f1a0ca",
              "IPY_MODEL_d54942daf8d0416f831e6bcec4572f6b",
              "IPY_MODEL_f6277bdc3d6e411092f5cb0d1f8be4a3"
            ],
            "layout": "IPY_MODEL_f3c39a7970f6486cb3de35568cca44cd"
          }
        },
        "5ca7565bdf814bb0a5494cdd2048c795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fd641cbadac4e9391dc0c823afc8324": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da97cbf5a1014b4e972bdc2ca435820e",
            "placeholder": "​",
            "style": "IPY_MODEL_c40aa0e088d5448f9dcbc1c74a3ace7f",
            "value": " 776/776 [00:00&lt;00:00, 72.7kB/s]"
          }
        },
        "6db0f68a255b4d91b9d6c203f953226e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7f0a3f130e4423dafac54eef9079a21",
            "placeholder": "​",
            "style": "IPY_MODEL_84256d738dc84ae7b2223be1c1d04a26",
            "value": "config.json: 100%"
          }
        },
        "82f6b70703d340d194450d0972fdef58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b788b2fe77b04835bce5c2186bf12b8c",
            "max": 776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d83e70344b6d41f3a7828fbcbf0c5b0c",
            "value": 776
          }
        },
        "84256d738dc84ae7b2223be1c1d04a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e7aeb08233a4151b9a4e88f8dadcff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "932f4a932f10415d8e3d527f248723e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa8070fb7ec44578ad9359edbdf5f65b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b788b2fe77b04835bce5c2186bf12b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40aa0e088d5448f9dcbc1c74a3ace7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7f0a3f130e4423dafac54eef9079a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54942daf8d0416f831e6bcec4572f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd9de31defc54a6c8864116119a5fca6",
            "max": 1326660716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ca7565bdf814bb0a5494cdd2048c795",
            "value": 1326660716
          }
        },
        "d83e70344b6d41f3a7828fbcbf0c5b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da97cbf5a1014b4e972bdc2ca435820e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9de31defc54a6c8864116119a5fca6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c39a7970f6486cb3de35568cca44cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6277bdc3d6e411092f5cb0d1f8be4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03660dd3c2434ffa8289ffb452d7d94a",
            "placeholder": "​",
            "style": "IPY_MODEL_932f4a932f10415d8e3d527f248723e5",
            "value": " 1.33G/1.33G [00:06&lt;00:00, 255MB/s]"
          }
        },
        "fa878a4d378842bcb6ffb857fcec7a22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
