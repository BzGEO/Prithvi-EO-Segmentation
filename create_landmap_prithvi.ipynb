{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Land Cover Mapping with Prithvi EO Model\n",
        "This notebook demonstrates the workflow for downloading satellite data, preprocessing, running inference with the Prithvi EO segmentation model, and merging results into a single GeoTIFF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easare377/Prithvi-EO-Segmentation/blob/main/create_landmap_prithvi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB1P92Gwocex",
        "outputId": "eec00164-0b1b-42b9-9063-893f1f421dde"
      },
      "outputs": [],
      "source": [
        "!pip install terratorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install Dependencies and Mount Google Drive\n",
        "Install required packages and mount Google Drive for data access and storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMQ4quluocex"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from osgeo import gdal\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMRe7x31qDUP",
        "outputId": "27e410e9-9577-4de7-a773-8eb69f33ea89"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoVecRdgocex"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import pathlib\n",
        "\n",
        "\n",
        "def download_file(url, dest_path, chunk_size=1024*1024):\n",
        "    \"\"\"\n",
        "    Download a large file from a URL with a progress bar.\n",
        "    Args:\n",
        "        url (str): File URL.\n",
        "        dest_path (str): Destination file path.\n",
        "        chunk_size (int): Download chunk size in bytes.\n",
        "    \"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    total = int(response.headers.get('content-length', 0))\n",
        "    with open(dest_path, 'wb') as file, tqdm(\n",
        "        desc=f\"Downloading {dest_path}\",\n",
        "        total=total,\n",
        "        unit='B',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in response.iter_content(chunk_size=chunk_size):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download and Prepare Satellite Data\n",
        "Download large satellite images and prepare them for processing and inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-dZbtouocey"
      },
      "outputs": [],
      "source": [
        "def zero_pad_array(input_array, new_shape):\n",
        "    \"\"\"\n",
        "    Zero-pad the input_array to the specified new_shape.\n",
        "    Args:\n",
        "        input_array (numpy.ndarray): Input array of shape (height, width, ...).\n",
        "        new_shape (tuple): Desired new shape (new_height, new_width, ...).\n",
        "    Returns:\n",
        "        numpy.ndarray: Zero-padded array of shape (new_height, new_width, ...).\n",
        "    \"\"\"\n",
        "    h, w = input_array.shape[:2]\n",
        "    new_h, new_w = new_shape[:2]\n",
        "    pad_h = max(new_h - h, 0)\n",
        "    pad_w = max(new_w - w, 0)\n",
        "    pad_values = [(0, pad_h), (0, pad_w)]\n",
        "    pad_values += [(0, 0)] * (input_array.ndim - 2)\n",
        "    return np.pad(input_array, pad_values, mode='constant', constant_values=0)\n",
        "\n",
        "def crop_np_array(arr, left, top, right, bottom):\n",
        "    \"\"\"\n",
        "    Crop the input NumPy array to the specified bounding box.\n",
        "\n",
        "    Args:\n",
        "        arr (numpy.ndarray): Input array to be cropped.\n",
        "        left (int): Left coordinate of the bounding box.\n",
        "        top (int): Top coordinate of the bounding box.\n",
        "        right (int): Right coordinate of the bounding box.\n",
        "        bottom (int): Bottom coordinate of the bounding box.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Cropped array within the specified bounding box.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the bounding box coordinates are invalid or exceed the array size.\n",
        "    \"\"\"\n",
        "    # Validate the bounding box coordinates\n",
        "    if left < 0 or top < 0 or right <= left or bottom <= top:\n",
        "        raise ValueError(\"Invalid bounding box coordinates.\")\n",
        "\n",
        "    # Get the dimensions of the input array\n",
        "    arr_height, arr_width = arr.shape[:2]\n",
        "\n",
        "    # Check if the bounding box exceeds the array size\n",
        "    if right > arr_width or bottom > arr_height:\n",
        "        raise ValueError(\"Bounding box exceeds the array size.\")\n",
        "\n",
        "    # Crop the array to the specified bounding box\n",
        "    cropped_arr = arr[top:bottom, left:right]\n",
        "\n",
        "    return cropped_arr\n",
        "\n",
        "def write_geoTiff_bands(output_raster, np_array, position):\n",
        "    \"\"\"\n",
        "    Write a numpy array to a GeoTIFF file.\n",
        "\n",
        "    Parameters:\n",
        "    - output_raster (gdal.Dataset): Output GeoTIFF dataset.\n",
        "    - np_array (numpy.ndarray): Numpy array to be written.\n",
        "    - position (tuple): Top-left position (left, top) to write the array in the GeoTIFF.\n",
        "    \"\"\"\n",
        "    array = np_array\n",
        "    left, top = position\n",
        "    height, width = array.shape[0], array.shape[1]\n",
        "    bands = array.shape[2]\n",
        "    for x in range(bands):\n",
        "        output_raster.GetRasterBand(x + 1).WriteArray(\n",
        "            array[:, :, x].reshape((height, width)), xoff=left, yoff=top)   # Writes my array to the raster\n",
        "    output_raster.FlushCache()\n",
        "\n",
        "\n",
        "def create_dir_if_not_exists(path):\n",
        "    if os.path.exists(path):\n",
        "        return\n",
        "    os.makedirs(path)\n",
        "\n",
        "\n",
        "def create_new_geoTiff(dest_path, size, band_count, projection, geo_transform, dtype=gdal.GDT_Byte, compression='DEFLATE', zlevel=9):\n",
        "    \"\"\"\n",
        "    Create a new GeoTIFF file with the specified dimensions, bands, projection, and geotransformation.\n",
        "\n",
        "    Parameters:\n",
        "        - dest_path (str): The path where the new GeoTIFF file will be created.\n",
        "        - size (tuple): A tuple specifying the width and height of the new GeoTIFF in pixels. (width, height)\n",
        "        - band_count (int): The number of bands in the new GeoTIFF.\n",
        "        - projection (str): The projection of the GeoTIFF file in Well-Known Text (WKT) format.\n",
        "        - geo_transform (tuple): A tuple representing the geotransformation parameters for the GeoTIFF.\n",
        "                               (originX, pixelWidth, 0, originY, 0, pixelHeight)\n",
        "        - dtype (int, optional): The data type of the pixel values in the new GeoTIFF. Default is gdal.GDT_Byte (8-bit).\n",
        "        - compression (str, optional): Compression method for the GeoTIFF. Default is 'DEFLATE'.\n",
        "        - zlevel (int, optional): Compression level for the GeoTIFF. Default is 5.\n",
        "    Returns:\n",
        "        gdal.Dataset: The GDAL dataset representing the newly created GeoTIFF file.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the GeoTIFF file with the specified dimensions\n",
        "    width, height = size\n",
        "    driver = gdal.GetDriverByName(\"GTiff\")\n",
        "    # Set compression options\n",
        "    options = ['COMPRESS=' + compression, 'ZLEVEL=' + str(zlevel)]\n",
        "    ds = driver.Create(dest_path, width, height,\n",
        "                       band_count, dtype, options=options)\n",
        "    # Define the projection of the file\n",
        "    ds.SetProjection(projection)\n",
        "    # Specify its coordinates\n",
        "    ds.SetGeoTransform(geo_transform)\n",
        "    return ds\n",
        "\n",
        "def get_geoTiff_extent(geoTiff, image_bounds=None):\n",
        "    \"\"\"\n",
        "    Get the geographic extent (bounding box) of a GeoTIFF.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (GDAL Dataset): Input GeoTIFF dataset object.\n",
        "    - image_bounds (tuple, optional): Bounds of the specific area of interest within the GeoTIFF.\n",
        "                                      Format: (xmin, xmax, ymin, ymax). Default is None,\n",
        "                                      which represents the entire extent of the GeoTIFF.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: Geographic extent (left, right, top, bottom) in the coordinate reference system of the GeoTIFF.\n",
        "\n",
        "    Note:\n",
        "    - The function assumes the input GeoTIFF is in a projected coordinate reference system (CRS).\n",
        "    - If image_bounds is provided, the extent will be calculated based on the specified bounds.\n",
        "      Otherwise, the entire extent of the GeoTIFF will be used.\n",
        "    - The returned extent represents the geographic coordinates (left, right, top, bottom)\n",
        "      within the CRS of the GeoTIFF.\n",
        "\n",
        "    Exceptions:\n",
        "    - ValueError: Raised if the image bounds are outside the valid range of the GeoTIFF.\n",
        "\n",
        "    \"\"\"\n",
        "    xmin_i, xres_i, xskew_i, ymin_i, yskew_r, yres_i = geoTiff.GetGeoTransform()\n",
        "    width, height = geoTiff.RasterXSize, geoTiff.RasterYSize\n",
        "    if image_bounds is None:\n",
        "        xmin, xmax, ymin, ymax = 0, geoTiff.RasterXSize, 0, geoTiff.RasterYSize\n",
        "    else:\n",
        "        xmin, xmax, ymin, ymax = image_bounds\n",
        "        if xmin < 0 or xmax > width or ymin < 0 or ymax > height:\n",
        "            raise ValueError(\n",
        "                \"Image bounds are outside the valid range of the GeoTIFF.\")\n",
        "    left = xmin_i + (xmin * xres_i)\n",
        "    right = xmin_i + (xmax * xres_i)\n",
        "    top = ymin_i + (ymin * yres_i)\n",
        "    bottom = ymin_i + (ymax * yres_i)\n",
        "    return (left, right, top, bottom)\n",
        "\n",
        "def get_geoTiff_datatype(geoTiff):\n",
        "    \"\"\"\n",
        "    Get the GDAL data type of a GeoTIFF dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "\n",
        "    Returns:\n",
        "    - int: GDAL data type of the GeoTIFF dataset.\n",
        "\n",
        "    \"\"\"\n",
        "    band = geoTiff.GetRasterBand(1)\n",
        "    return band.DataType\n",
        "\n",
        "def get_geoTiff_numpy_datatype(geoTiff):\n",
        "    \"\"\"\n",
        "    Get the NumPy data type string of a GeoTIFF dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "\n",
        "    Returns:\n",
        "    - str: NumPy data type string of the GeoTIFF dataset.\n",
        "\n",
        "    \"\"\"\n",
        "    gt_dtype = get_geoTiff_datatype(geoTiff)\n",
        "    gdal_to_numpy_datatype = {\n",
        "        gdal.GDT_Byte: 'uint8',\n",
        "        gdal.GDT_UInt16: 'uint16',\n",
        "        gdal.GDT_Int16: 'int16',\n",
        "        gdal.GDT_UInt32: 'uint32',\n",
        "        gdal.GDT_Int32: 'int32',\n",
        "        gdal.GDT_Float32: 'float32',\n",
        "        gdal.GDT_Float64: 'float64'\n",
        "    }\n",
        "    numpy_datatype = gdal_to_numpy_datatype.get(gt_dtype, None)\n",
        "    return numpy_datatype\n",
        "\n",
        "\n",
        "def crop_geoTiff(geoTiff, left, top, right, bottom, dtype=None):\n",
        "    \"\"\"\n",
        "    Crop a GeoTIFF array to the specified region.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "    - left (int): Left coordinate of the crop region.\n",
        "    - top (int): Top coordinate of the crop region.\n",
        "    - right (int): Right coordinate of the crop region.\n",
        "    - bottom (int): Bottom coordinate of the crop region.\n",
        "    - dtype (str or None, optional): Desired data type of the output array.\n",
        "    If set to None, the data type is inferred from the band. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    - output (numpy.ndarray): Cropped array with dimensions (height, width, bands).\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the crop dimensions exceed the size of the GeoTIFF.\n",
        "    \"\"\"\n",
        "    if (int(right) > geoTiff.RasterXSize) or (int(bottom) > geoTiff.RasterYSize):\n",
        "        # print(right, bottom)\n",
        "        # print(geoTiff.RasterXSize, geoTiff.RasterYSize)\n",
        "        raise ValueError('Crop dimensions exceed the size of the GeoTIFF.')\n",
        "    if dtype is None:\n",
        "        dtype = get_geoTiff_numpy_datatype(geoTiff)\n",
        "    width = abs(right - left)\n",
        "    height = abs(top - bottom)\n",
        "    output = np.zeros(\n",
        "        (int(height), int(width), geoTiff.RasterCount), dtype)\n",
        "    # bands = [None] * geoTiff.RasterCount\n",
        "    for x in range(geoTiff.RasterCount):\n",
        "        band = geoTiff.GetRasterBand(x + 1).ReadAsArray(left, top,\n",
        "                                                        int(width), int(height))\n",
        "        output[..., x] = band\n",
        "    return output\n",
        "\n",
        "def get_geoTiff_part(geoTiff, left, top, right, bottom, dtype='uint16'):\n",
        "    c_gt = crop_geoTiff(geoTiff, left, top, right, bottom, dtype)\n",
        "    extent = get_geoTiff_extent(geoTiff, (left, right, top, bottom))\n",
        "    return c_gt, extent\n",
        "\n",
        "def crop_geoTiff_into_grids(geoTiff, max_grid_shape, yield_results=False, dtype = 'uint16'):\n",
        "    \"\"\"\n",
        "    Split a GeoTIFF into grids of numpy arrays with a specified maximum shape.\n",
        "\n",
        "    Parameters:\n",
        "    - geoTiff (gdal.Dataset): Input GeoTIFF dataset.\n",
        "    - max_grid_shape (tuple): Maximum shape of each grid (rows, columns).\n",
        "    - yield_results (bool, optional): Whether to yield each grid individually or return all grids in a list.\n",
        "                                      Defaults to True (yield results).\n",
        "\n",
        "    Yields or Returns:\n",
        "    - grid (numpy.ndarray): Numpy array representing a divided grid.\n",
        "      (Yielded if yield_results=True, Returned as a list if yield_results=False)\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the max_grid_shape is invalid or exceeds the size of the GeoTIFF.\n",
        "    \"\"\"\n",
        "    if not isinstance(max_grid_shape, tuple) or len(max_grid_shape) != 2 or \\\n",
        "       max_grid_shape[0] <= 0 or max_grid_shape[1] <= 0:\n",
        "        raise ValueError(\n",
        "            \"Invalid max_grid_shape. It should be a tuple of two positive integers.\")\n",
        "\n",
        "    if max_grid_shape[0] > geoTiff.RasterYSize or max_grid_shape[1] > geoTiff.RasterXSize:\n",
        "        raise ValueError(\"max_grid_shape exceeds the size of the GeoTIFF.\")\n",
        "\n",
        "    rows, cols = geoTiff.RasterYSize, geoTiff.RasterXSize\n",
        "    max_grid_height, max_grid_width = max_grid_shape\n",
        "    total_grids = np.ceil(rows / max_grid_height) * np.ceil(cols / max_grid_width)\n",
        "    if yield_results:\n",
        "        progress = 0\n",
        "        for r in range(0, rows, max_grid_height):\n",
        "            for c in range(0, cols, max_grid_width):\n",
        "                left, top = c, r\n",
        "                right, bottom = min(\n",
        "                    c + max_grid_width, cols), min(r + max_grid_height, rows)\n",
        "\n",
        "                grid, extent = get_geoTiff_part(\n",
        "                    geoTiff, left, top, right, bottom, dtype)\n",
        "                progress += 1\n",
        "                yield (grid, extent, (left, top, right, bottom), (progress, total_grids))\n",
        "    else:\n",
        "        grids = []\n",
        "        for r in range(0, rows, max_grid_height):\n",
        "            for c in range(0, cols, max_grid_width):\n",
        "                left, top = c, r\n",
        "                right, bottom = min(\n",
        "                    c + max_grid_width, cols), min(r + max_grid_height, rows)\n",
        "\n",
        "                grid, extent = get_geoTiff_part(\n",
        "                    geoTiff, left, top, right, bottom)\n",
        "                grids.append((grid, extent, (left, top, right, bottom)))\n",
        "        return grids\n",
        "\n",
        "def crop_and_process_geoTiff(geoTiff, process_func, max_grid_shape=None, dtype = 'uint16'):\n",
        "    \"\"\"\n",
        "    Split a GeoTIFF into grids, process each grid, and write the processed grids to an output GeoTIFF.\n",
        "\n",
        "    Parameters:\n",
        "    - dataset (gdal.Dataset): Input GeoTIFF dataset.\n",
        "    - max_grid_shape (tuple): Maximum shape of each grid (rows, columns).\n",
        "    - output_tiff (str): Output GeoTIFF file path.\n",
        "    Raises:\n",
        "    - ValueError: If the max_grid_shape is invalid or exceeds the size of the GeoTIFF.\n",
        "    \"\"\"\n",
        "    if max_grid_shape is None:\n",
        "        max_grid_shape = geoTiff.RasterYSize, geoTiff.RasterXSize\n",
        "    if not isinstance(max_grid_shape, tuple) or len(max_grid_shape) != 2 or \\\n",
        "       max_grid_shape[0] <= 0 or max_grid_shape[1] <= 0:\n",
        "        raise ValueError(\n",
        "            \"Invalid max_grid_shape. It should be a tuple of two positive integers.\")\n",
        "\n",
        "    if max_grid_shape[0] > geoTiff.RasterYSize or max_grid_shape[1] > geoTiff.RasterXSize:\n",
        "        raise ValueError(\"max_grid_shape exceeds the size of the GeoTIFF.\")\n",
        "\n",
        "    # Iterate over each grid individually\n",
        "    for i, grid in enumerate(crop_geoTiff_into_grids(geoTiff, max_grid_shape, True, dtype)):\n",
        "        # Process each grid (Replace with your processing code)\n",
        "        np_gt_part, extent, image_coord, progress = grid\n",
        "        processed_grid = process_func(np_gt_part, extent, image_coord, progress)\n",
        "\n",
        "def get_file_or_foldername(path):\n",
        "    return os.path.basename(path)\n",
        "\n",
        "def real_image_preprocessing_func(np_gt):\n",
        "    \"\"\"\n",
        "    1) Clip the raw array to [0, 6000].\n",
        "    2) Normalize each band using the provided mean and std (computed from raw data).\n",
        "    3) Clip the result to [0, 1].\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure float32\n",
        "    np_gt = np_gt.astype(np.float32)\n",
        "\n",
        "    # Provided normalization statistics for raw values (0..6000 range):\n",
        "    data_mean = np.array([1635.8452, 1584.4594, 1456.8425, 2926.6663, 2135.001, 1352.7313], dtype=np.float32)\n",
        "\n",
        "    data_std = np.array([884.3994, 815.4016, 839.0293, 1055.6382, 751.4628, 628.5323], dtype=np.float32)\n",
        "\n",
        "\n",
        "    # 1) Clip the raw values to [0..6000]\n",
        "    #np_gt = np.clip(np_gt, 0, 6000)\n",
        "\n",
        "    # 2) Bandwise normalization: (value - mean) / std\n",
        "    #    Assuming np_gt has shape (H, W, 6), broadcasting will apply along the last dimension\n",
        "    np_gt = (np_gt - data_mean) / data_std\n",
        "\n",
        "    # 3) Finally, clip to [0..1] if desired\n",
        "    #np_gt = np.clip(np_gt, 0, 1)\n",
        "\n",
        "    return np_gt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing and Utility Functions\n",
        "Define helper functions for padding, cropping, writing GeoTIFFs, and preprocessing images for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0wCpS6csIj_",
        "outputId": "ee26401f-2877-475d-b89d-b8d476da0a2c"
      },
      "outputs": [],
      "source": [
        "dest_path = '/content/drive/MyDrive/SCO_training/sentinel_images'\n",
        "geotiff_image_path = os.path.join(dest_path, '2023.tif')\n",
        "#create_dir_if_not_exists(dest_path)\n",
        "download_file('https://sco-training.s3.us-east-2.amazonaws.com/2024.tif', geotiff_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNJlD6vusOKP",
        "outputId": "2d13ef4f-c81c-41af-d124-a7e9e66978b1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoQehs9Qocey"
      },
      "outputs": [],
      "source": [
        "def predict_mask(unet, np_img, input_shape):\n",
        "    # Zero-pad if needed\n",
        "    height, width = np_img.shape[:2]\n",
        "    target_height, target_width = input_shape\n",
        "    # Preprocess\n",
        "    np_img = real_image_preprocessing_func(np_img)\n",
        "    if (height != target_height) or (width != target_width):\n",
        "        np_img = zero_pad_array(np_img, (target_height, target_width))\n",
        "    # Convert to torch tensor [B, C, H, W]\n",
        "    img_tensor = torch.from_numpy(np_img).permute(2, 0, 1).unsqueeze(0)\n",
        "    img_tensor = img_tensor.float().to(device)\n",
        "    # Inference\n",
        "    unet.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = unet(img_tensor).output  # [1, n_classes, H, W]\n",
        "    # Argmax -> [H, W]\n",
        "    pred_mask = logits.argmax(dim=1).squeeze(0).cpu().numpy()\n",
        "    # Crop back if zero-padded\n",
        "    pred_mask = crop_np_array(pred_mask, 0, 0, width, height)\n",
        "    #print(pred_mask.shape)\n",
        "    pred_mask = pred_mask.reshape((pred_mask.shape[0], pred_mask.shape[1], 1))\n",
        "    return pred_mask\n",
        "\n",
        "\n",
        "def pre_process_func(dest_gt, model, max_grid_shape):\n",
        "    def predict_grid(np_gt, extent, image_coord, progress):\n",
        "        mask_np_gt = predict_mask(model, np_gt, max_grid_shape)\n",
        "        position = image_coord[0], image_coord[1]\n",
        "        #print(mask_np_gt.shape)\n",
        "        write_geoTiff_bands(dest_gt, mask_np_gt, position)\n",
        "        # Optionally log progress\n",
        "    return predict_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioTJfkt3ocez"
      },
      "outputs": [],
      "source": [
        "# Usage example\n",
        "def run_inference(gt_paths, prediction_path, mc_unet):\n",
        "    # Move model to GPU (if available) once\n",
        "    mc_unet.to(device)\n",
        "    mc_unet.eval()\n",
        "\n",
        "    dest_path = prediction_path\n",
        "    create_dir_if_not_exists(dest_path)\n",
        "\n",
        "    for gt_path in gt_paths:\n",
        "        dest_file = os.path.join(dest_path, get_file_or_foldername(gt_path))\n",
        "        if os.path.exists(dest_file):\n",
        "            print(\"skipping\", dest_file)\n",
        "            continue\n",
        "\n",
        "        print(\"Processing\", gt_path)\n",
        "        gt = gdal.Open(gt_path)\n",
        "        proj = gt.GetProjection()\n",
        "        size = gt.RasterXSize, gt.RasterYSize\n",
        "        geo_transform = gt.GetGeoTransform()\n",
        "\n",
        "        dest_gt = create_new_geoTiff(dest_file, size, 1, proj, geo_transform, compression=\"None\")\n",
        "        tile_callback = pre_process_func(dest_gt, mc_unet, (224, 224))\n",
        "\n",
        "        crop_and_process_geoTiff(gt, tile_callback, (224, 224), 'uint16')\n",
        "        gt = None\n",
        "        dest_gt = None\n",
        "        print(dest_file, \"saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Inference and Save Predictions\n",
        "Run the Prithvi EO segmentation model on satellite images and save predicted masks as GeoTIFFs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldXXdMjXocez",
        "outputId": "d71f7081-d766-48f9-da33-42468f6b30b4"
      },
      "outputs": [],
      "source": [
        "from terratorch.tasks import SemanticSegmentationTask\n",
        "\n",
        "model = SemanticSegmentationTask(\n",
        "    model_factory=\"EncoderDecoderFactory\",\n",
        "    model_args=dict(\n",
        "        backbone=\"terratorch_prithvi_eo_v2_300_tl\",\n",
        "        backbone_pretrained=False,\n",
        "        backbone_img_size=224,\n",
        "        backbone_bands=[\"BLUE\",\"GREEN\",\"RED\",\"NIR_NARROW\",\"SWIR_1\",\"SWIR_2\"],\n",
        "        necks=[{\"name\":\"SelectIndices\", \"indices\":[1, 5,11,17,23]},\n",
        "               {\"name\":\"ReshapeTokensToImage\"}],\n",
        "        decoder=\"FCNDecoder\",\n",
        "        decoder_channels=256,\n",
        "        num_classes=3,\n",
        "        head_dropout=0.1,\n",
        "    ),\n",
        "    freeze_backbone=False,\n",
        "    freeze_decoder=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAPIJBvCocez",
        "outputId": "72bdbbc7-964a-42ef-d6e9-5226944fef97"
      },
      "outputs": [],
      "source": [
        "model_save_path  = Path(\"/content/drive/MyDrive/SCO_training/prithvi_state_dict.pt\")\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th54G6tBocez",
        "outputId": "2abb0cbd-7294-464c-dc81-b55a99c66a21"
      },
      "outputs": [],
      "source": [
        "total_elements = sum(p.numel() for p in model.model.encoder.parameters())\n",
        "print(f\"Total encoder parameter elements: {total_elements}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmIbTKoAvM5r"
      },
      "outputs": [],
      "source": [
        "def get_all_files(path, pattern='*', get_full_path=False):\n",
        "    files = list(pathlib.Path(path).glob(pattern))\n",
        "    if get_full_path:\n",
        "        onlyfiles = [os.path.join(path, f.name) for f in files if f.is_file()]\n",
        "    else:\n",
        "        onlyfiles = [f.name for f in files if f.is_file()]\n",
        "    return onlyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk-JmRPjocez",
        "outputId": "c2297141-7ab8-413a-9438-5ef563647150"
      },
      "outputs": [],
      "source": [
        "gt_paths = get_all_files(\n",
        "    '/content/drive/MyDrive/SCO_training/sentinel_images', '*.tif', True)\n",
        "len(gt_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyx2AOKgocez",
        "outputId": "bad66d70-3a0e-462c-d88d-5c7f80997877"
      },
      "outputs": [],
      "source": [
        "dest = '/content/drive/MyDrive/SCO_training/footprints'\n",
        "create_dir_if_not_exists(dest)\n",
        "run_inference(gt_paths, dest, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqHTqPuHocez",
        "outputId": "6af83fd9-62b2-4a91-ba7e-ef3048236584"
      },
      "outputs": [],
      "source": [
        "geoTiff_paths = iu.get_all_files(dest, '*.tif', True)\n",
        "len(geoTiff_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXu7qQQjoce0"
      },
      "outputs": [],
      "source": [
        "def merge_geoTiffs(geoTiff_paths, output_path, compression='NONE'):\n",
        "    \"\"\"\n",
        "    Merge multiple GeoTIFF files into a single GeoTIFF file.\n",
        "    \"\"\"\n",
        "    from osgeo import gdal\n",
        "\n",
        "    # Open each input GeoTIFF file read-only\n",
        "    geoTiffs = [gdal.Open(path, gdal.GA_ReadOnly) for path in geoTiff_paths]\n",
        "\n",
        "    # Option 1: pass format to gdal.Warp, pass a WarpOptions object via warpOptions\n",
        "    warp_options = gdal.WarpOptions(options=['COMPRESS=' + compression])\n",
        "    g = gdal.Warp(output_path, geoTiffs, format='GTiff', warpOptions=warp_options)\n",
        "    g = None  # Close dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge Predicted GeoTIFFs\n",
        "Combine multiple predicted GeoTIFF files into a single output for visualization or further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnMt7Jfzoce0"
      },
      "outputs": [],
      "source": [
        "merge_geoTiffs(\n",
        "    geoTiff_paths, 'C:\\\\Users\\\\emmanuelasare\\\\Downloads\\\\sentinel-aoi-2025(2025-7-22).tif',  'LZW')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
